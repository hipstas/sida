{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import attk\n",
    "import csv\n",
    "import joblib\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from IPython.display import display, Audio\n",
    "import timeit\n",
    "import random\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "random.seed(9998) ## Seeding random number generator for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = \"Potential_WGBH_tones_2887_classifier_4K_batch.csv\"\n",
    "\n",
    "completed_this_session=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## RESUME HERE WHEN USING PRE-TRAINED MODEL ########\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extra_trees=joblib.load('aapb_test_tones_extra_trees.pkl')\n",
    "\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPB_Subset_4000/cpb-aacip-86-20sqvd9q.h264.mp4',\n",
       " 'AAPB_Subset_4000/cpb-aacip-77-02q57zt0.h264.mp4',\n",
       " 'AAPB_Subset_4000/cpb-aacip-15-rr1pg1jc1z__IHUB-A_.mp3',\n",
       " '...']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a list of all media pathnames within a directory \n",
    "## (including subdirectories)\n",
    "\n",
    "#media_paths = attk.find_media_paths('AAPB_Subset_4000/')\n",
    "\n",
    "media_paths = ['AAPB_Subset_4000/'+item for item in os.listdir('AAPB_Subset_4000/') if item[-4:].lower() in ('.mp3','.mp4','.wav')]\n",
    "\n",
    "media_paths[:3]+['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating a list of files that have already been classified (in case we get interrupted)\n",
    "\n",
    "completed_filenames=[]\n",
    "\n",
    "with open(csv_path) as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            completed_filenames.append(row[0])\n",
    "        except:\n",
    "            print(\"Problem loading: \"+str(row))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: os.mkdir('temp_clip')\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4834\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "def update_completed_list():\n",
    "    completed_filenames = copy(completed_this_session)\n",
    "\n",
    "    with open(csv_path) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            try:\n",
    "                completed_filenames.append(row[0])\n",
    "            except:\n",
    "                print(\"Problem loading: \"+str(row))\n",
    "\n",
    "update_completed_list()\n",
    "print len(list(set(completed_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function version of the script above, for multithreading\n",
    "\n",
    "def classify_and_save(media_path):\n",
    "    \n",
    "    ## Starting timer\n",
    "    tic=timeit.default_timer()\n",
    "    \n",
    "    completed_this_session.append(media_path.split('/')[-1])\n",
    "    \n",
    "    try:\n",
    "        if media_path.split('/')[-1] not in completed_filenames: ## Checking whether file\n",
    "                                                                 ## been classified already\n",
    "\n",
    "            ## Creating temporary WAV excerpt and extracting features\n",
    "            clip_pathname = attk.subclip(media_path,0,80,'temp_clip/')  ## first 80 seconds\n",
    "            test_mfccs = attk.get_mfccs_and_deltas(clip_pathname)\n",
    "            \n",
    "            ## Classifying audio\n",
    "            results = extra_trees.predict(test_mfccs)\n",
    "            print(list(results[:150])+['...'])\n",
    "            \n",
    "            ## Smoothing and filtering output\n",
    "            smoothed_ranges = attk.labels_to_ranges( \\\n",
    "                        [round(item) for item in attk.smooth(results, window_len=10)], \\\n",
    "                        label=0)\n",
    "            \n",
    "            confirmed_tones=[]\n",
    "            \n",
    "            if len(smoothed_ranges)>0:\n",
    "                for pair in smoothed_ranges:\n",
    "                    start, end = pair\n",
    "                    if (end-start) > 5:\n",
    "                        start_time = (80.0/len(results))*start         \n",
    "                        end_time = (80.0/len(results))*(end+5)\n",
    "                        confirmed_tones.append((start_time,end_time))\n",
    "            \n",
    "            ## Writing positive classification ranges to CSV\n",
    "            with open(csv_path,'a') as csvfile:\n",
    "                csvwriter = csv.writer(csvfile)\n",
    "            \n",
    "                for pair in confirmed_tones:\n",
    "                    start, end = pair\n",
    "                    csvwriter.writerow([media_path.split('/')[-1],str(round(start,4)),str(round(end,4))])\n",
    "            \n",
    "                if len(confirmed_tones)==0:\n",
    "                    csvwriter.writerow([media_path.split('/')[-1],'',''])\n",
    "            \n",
    "            ## Deleting temporary WAV clip\n",
    "            try: os.remove(clip_pathname)\n",
    "            except: print \"** Error: Can't remove \"+clip_pathname\n",
    "\n",
    "    ## Printing and storing errors\n",
    "    except Exception as e:\n",
    "        error_pair=(media_path,e)\n",
    "        print(error_pair)\n",
    "        errors.append(error_pair)\n",
    "        try: os.remove(clip_pathname)\n",
    "        except: pass\n",
    "    \n",
    "    time.sleep(random.random()*3)\n",
    "    \n",
    "    ## Printing time elapsed\n",
    "    print(\"Time elapsed: \"+str(timeit.default_timer() - tic))\n",
    "    if float(timeit.default_timer() - tic) > 0.5:\n",
    "        print \"***\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Classifying in parallel batches of 4\n",
    "\n",
    "errors=[]\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "pool_size = 4\n",
    "\n",
    "pool = Pool(pool_size)\n",
    "\n",
    "for i in range(1000):\n",
    "    tic=timeit.default_timer()\n",
    "    pool_media_paths=[]\n",
    "    \n",
    "    #pool = Pool(pool_size)\n",
    "    \n",
    "    for j in range(pool_size):\n",
    "        media_path = random.choice(media_paths)\n",
    "        update_completed_list()\n",
    "        counter=0\n",
    "        while media_path.split('/')[-1] in completed_filenames:\n",
    "            media_path = random.choice(media_paths)\n",
    "            counter+=1\n",
    "            if counter>10000:\n",
    "                print(\"Looks like you might be done.\")\n",
    "                break\n",
    "                break\n",
    "                break\n",
    "        pool_media_paths.append(media_path)\n",
    "\n",
    "    print(pool_media_paths)\n",
    "    pool.map(classify_and_save, pool_media_paths)\n",
    "    print(\"Time elapsed: \"+str(timeit.default_timer() - tic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Time elapsed: \"+str(timeit.default_timer() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
