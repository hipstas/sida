{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIDA: Speaker Identification for Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "import pandas as pd\n",
    "\n",
    "!mkdir -p /sharedfolder/sida_classifier/\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "training_audio_dir_name = \"Applause\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "#!wget http://xtra.arloproject.com/datasets/audio/Mozilla_CV_UBM_Subset/females_5k.zip\n",
    "#!wget http://xtra.arloproject.com/datasets/audio/Mozilla_CV_UBM_Subset/males_5k.zip\n",
    "#!wget http://xtra.arloproject.com/datasets/aapb-ubm/Male_AAPB_171110.zip\n",
    "#!wget http://xtra.arloproject.com/datasets/aapb-ubm/Female_AAPB_171110.zip\n",
    "\n",
    "#!unzip females_5k.zip\n",
    "#!unzip males_5k.zip\n",
    "#!unzip Male_AAPB_171110.zip\n",
    "#!unzip Female_AAPB_171110.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!mv females_5k Larry_Monroe/\n",
    "#!mv males_5k Larry_Monroe/\n",
    "#!mv Male_AAPB_171110 Larry_Monroe/\n",
    "#!mv Female_AAPB_171110 Larry_Monroe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/hipstas/applause-classifier.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load 1-second labels\n",
    "\n",
    "#csv_path = '/sharedfolder/sida_classifier/LM_random_labels_5K.csv'\n",
    "\n",
    "#train_table_df = pd.read_csv(csv_path)\n",
    "\n",
    "#train_table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing variables to extract and assigning variables we'll use below\n",
    "\n",
    "labels_to_use = ['Laughter', 'Non-Laughter']\n",
    "\n",
    "media_dir_pathname = '/sharedfolder/sida_classifier/' + training_audio_dir_name\n",
    "\n",
    "class_dir_pathname = '/sharedfolder/sida_classifier/_classes_' + training_audio_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## should be able to delete this cell next time \n",
    "\n",
    "from attk import *\n",
    "\n",
    "import itertools\n",
    "\n",
    "def batch_extract_vowels(media_dir):\n",
    "    starting_location = os.getcwd()\n",
    "    os.chdir(media_dir)\n",
    "    try:\n",
    "        os.mkdir('_vowel_clips')\n",
    "    except:\n",
    "        pass\n",
    "    filenames = [item for item in os.listdir('./') if item[-4:].lower() in ('.mp3', '.wav', '.mp4')]\n",
    "    for filename in filenames:\n",
    "        vowel_bools = get_vowel_segments(filename, n_fft = 4096)   ##  <- edit\n",
    "        vowel_ranges = labels_to_ranges(vowel_bools, label=True)\n",
    "        sample_rate_val = sample_rate(filename)\n",
    "        vowel_ranges_secs = []\n",
    "        for pair in vowel_ranges:\n",
    "            try:\n",
    "                start_samples, end_samples = pair\n",
    "                duration_samples = int(end_samples) - int(start_samples)\n",
    "                start = float(start_samples) * (float(4096) / sample_rate_val)\n",
    "                duration_secs = float(duration_samples) * (float(4096) / sample_rate_val)\n",
    "                #if duration_secs >= 0.05:                                             # discarding vowel segments shorter than 0.05 sec\n",
    "                vowel_ranges_secs.append((start, duration_secs))\n",
    "            except Exception as e:\n",
    "                print('ERROR: ' + filename)\n",
    "                print(e)\n",
    "        subclip_list(filename, vowel_ranges_secs, '_vowel_clips')\n",
    "    os.chdir(starting_location)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def get_vowel_segments(media_path, n_fft=2048):\n",
    "    downsample = 1\n",
    "    samplerate = 44100 // downsample\n",
    "\n",
    "    win_s = n_fft // downsample # fft size\n",
    "    hop_s = n_fft  // downsample # hop size\n",
    "\n",
    "    s = source(media_path, samplerate, hop_s)\n",
    "    samplerate = s.samplerate\n",
    "\n",
    "    tolerance = 0.6\n",
    "\n",
    "    pitch_o = pitch(\"yin\", win_s, hop_s, samplerate)\n",
    "    pitch_o.set_unit(\"Hz\")\n",
    "    pitch_o.set_tolerance(tolerance)\n",
    "\n",
    "    pitches = []\n",
    "    confidences = []\n",
    "\n",
    "    # total number of frames read\n",
    "    total_frames = 0\n",
    "    samples=[]\n",
    "    pitches=[]\n",
    "    while True:\n",
    "        samples, read = s()\n",
    "        pitch_ = pitch_o(samples)[0]\n",
    "        #pitch = int(round(pitch))\n",
    "        confidence = pitch_o.get_confidence()\n",
    "        #print(\"%f %f %f\" % (total_frames / float(samplerate), pitch, confidence))\n",
    "        pitches += [pitch_]\n",
    "        confidences += [confidence]\n",
    "        total_frames += read\n",
    "        if read < hop_s: break\n",
    "\n",
    "    pitches = np.array(pitches)\n",
    "    confidences = np.array(confidences)\n",
    "\n",
    "    cleaned_pitches = ma.masked_where(confidences < tolerance, pitches)\n",
    "    cleaned_pitches = ma.masked_where(cleaned_pitches > 1000, cleaned_pitches)\n",
    "\n",
    "    try: output = list(np.logical_not(cleaned_pitches.mask))\n",
    "    except: output = []\n",
    "\n",
    "    return output\n",
    "\n",
    "def labels_to_ranges(label_list,label=0):\n",
    "    counter=0\n",
    "    seq_list=[]\n",
    "    for item in label_list:\n",
    "        if item==label:\n",
    "            seq_list.append(counter)\n",
    "        counter+=1\n",
    "    ranges = [(t[0][1], t[-1][1]+1) for t in (tuple(g[1]) for g in itertools.groupby(enumerate(seq_list), lambda (i, x): i - x))]\n",
    "    return ranges\n",
    "\n",
    "\n",
    "def sample_rate(media_path):\n",
    "    return int(subprocess.check_output(['ffprobe', '-v', '0', '-of', 'csv=p=0', '-select_streams', '0', '-show_entries', 'stream=sample_rate', media_path]).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '/sharedfolder/sida_classifier/_classes_Applause'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Extract features (MFCCs, deltas, and delta-deltas) from all clips, then write features to CSVs\n",
    "\n",
    "os.chdir(class_dir_pathname)\n",
    "\n",
    "for dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "    print(\"> Starting \" + dir_name)\n",
    "    try:\n",
    "        os.chdir(os.path.join(class_dir_pathname, dir_name))\n",
    "        try: os.mkdir('./_mfccs_and_deltas')\n",
    "        except: pass\n",
    "        filenames = [item for item in os.listdir('./') if item[-4:].lower()=='.wav']\n",
    "        for filename in filenames:\n",
    "            csv_out_path = './_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv'\n",
    "            if not os.path.isfile(csv_out_path):\n",
    "                try:\n",
    "                    mfccs = attk.get_mfccs_and_deltas(filename, n_mfcc=30, n_fft=4096, freq_min=100, freq_max=16000)\n",
    "                    if len(mfccs) > 0:\n",
    "                        with open(csv_out_path, 'w') as fo:\n",
    "                            csv_writer = csv.writer(fo)\n",
    "                            csv_writer.writerows(mfccs)  \n",
    "                except Exception as e:\n",
    "                    print('FILE ERROR: ' + filename)\n",
    "                    print(e)\n",
    "    except Exception as e:\n",
    "        print('SKIPPING DIRECTORY: ' + dir_name)     ## Skipping class directories for which we didn't extract vowels\n",
    "        #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue to the next notebook to train and run the speaker ID classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
