{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIDA: Speaker Identification for Archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install git+git://github.com/hipstas/audio-tagging-toolkit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "import pandas as pd\n",
    "\n",
    "!mkdir -p /sharedfolder/sida_classifier/\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "## Download audio files for training\n",
    "#### (You may want to comment out the lines below once the download is complete.)\n",
    "#!wget -N http://xtra.arloproject.com/datasets/audio/The_World_WGBH_100_episodes.zip\n",
    "#!unzip The_World_WGBH_100_episodes.zip\n",
    "\n",
    "training_audio_dir_name = \"Obama_training_clips_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download new 1-second labels\n",
    "\n",
    "csv_url = \"https://raw.githubusercontent.com/hipstas/aapb-speaker-labels/master/speaker_labels_randomized/The_World_WGBH_labels_100_episodes.csv\"\n",
    "\n",
    "csv_string = urllib2.urlopen(csv_url)\n",
    "\n",
    "train_table_df = pd.read_csv(csv_url)\n",
    "\n",
    "train_table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Choosing variables to extract and assigning variables we'll use below\n",
    "\n",
    "labels_to_use = ['Barack Obama']\n",
    "\n",
    "media_dir_pathname = '/sharedfolder/sida_classifier/' + training_audio_dir_name\n",
    "\n",
    "class_dir_pathname = '/sharedfolder/sida_classifier/_classes_' + training_audio_dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Excerpting WAV clips corresponding to labels\n",
    "#### (This may take a while.)\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "train_table_groups = train_table_df.groupby(['Media file basename', 'Label'])\n",
    "\n",
    "for name, group in train_table_groups:\n",
    "    list_of_lists = group.values.tolist()\n",
    "    basename, start, duration, label, labeled_by = list_of_lists[0]\n",
    "    filename = str(basename) + '.mp3'\n",
    "    media_path = os.path.join(media_dir_pathname, filename)\n",
    "    label_dir_pathname = str(os.path.join(class_dir_pathname, label.replace(' ','_')))\n",
    "    if label in labels_to_use:\n",
    "        subclip_pairs = []\n",
    "        for row in list_of_lists:\n",
    "            basename, start, duration, label, labeled_by = row\n",
    "            subclip_pairs.append((float(start), float(duration)))\n",
    "        try: subprocess.call(['mkdir', '-p', label_dir_pathname])\n",
    "        except: pass\n",
    "        try:\n",
    "            attk.subclip_list(media_path, subclip_pairs, label_dir_pathname)\n",
    "        except Exception as e: \n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Extract vowel segments from labeled audio clips\n",
    "#### (This may take a while.)\n",
    "\n",
    "os.chdir(class_dir_pathname)\n",
    "\n",
    "for dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "    try:\n",
    "        attk.batch_extract_vowels(dir_name)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: \" + dir_name)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Extract features (MFCCs, deltas, and delta-deltas) from Obama vowel clips, then write features to CSVs\n",
    "\n",
    "os.chdir(class_dir_pathname)\n",
    "\n",
    "for dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "    print(\"> Starting \" + dir_name)\n",
    "    try:\n",
    "        os.chdir(os.path.join(class_dir_pathname, dir_name, '_vowel_clips'))\n",
    "        try: os.mkdir('../_vowel_mfccs_and_deltas')\n",
    "        except: pass\n",
    "        filenames = [item for item in os.listdir('./') if item[-4:].lower()=='.wav']\n",
    "        for filename in filenames:\n",
    "            csv_out_path = '../_vowel_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv'\n",
    "            if not os.path.isfile(csv_out_path):\n",
    "                try:\n",
    "                    mfccs = attk.get_mfccs_and_deltas(filename)\n",
    "                    if len(mfccs) > 0:\n",
    "                        with open(csv_out_path, 'w') as fo:\n",
    "                            csv_writer = csv.writer(fo)\n",
    "                            csv_writer.writerows(mfccs)  \n",
    "                except Exception as e:\n",
    "                    print('FILE ERROR: ' + filename)\n",
    "                    print(e)\n",
    "    except Exception as e:\n",
    "        print('SKIPPING DIRECTORY: ' + dir_name)     ## Skipping class directories for which we didn't extract vowels\n",
    "        #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Download and unzip prepared UBM feature set\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "!wget -q https://github.com/hipstas/aapb-ubm/blob/master/UBM_feature_set/AAPB_female_vowel_mfccs_and_deltas.zip?raw=true -O AAPB_female_vowel_mfccs_and_deltas.zip\n",
    "!wget -q https://github.com/hipstas/aapb-ubm/blob/master/UBM_feature_set/AAPB_male_vowel_mfccs_and_deltas.zip?raw=true -O AAPB_male_vowel_mfccs_and_deltas.zip\n",
    "\n",
    "!unzip AAPB_female_vowel_mfccs_and_deltas.zip\n",
    "!unzip AAPB_male_vowel_mfccs_and_deltas.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Continue to the next notebook to train and run the speaker ID classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
