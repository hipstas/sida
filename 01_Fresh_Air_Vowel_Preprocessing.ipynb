{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install the latest version of attk (if necessary)\n",
    "#!pip install -U git+git://github.com/hipstas/audio-tagging-toolkit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory '/sharedfolder/GitHub/sida/___training_audio': File exists\r\n"
     ]
    }
   ],
   "source": [
    "import attk\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from IPython.display import display, Audio\n",
    "import timeit\n",
    "import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "import csv\n",
    "\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/')\n",
    "\n",
    "!mkdir /sharedfolder/GitHub/sida/___training_audio\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio')\n",
    "\n",
    "## Uncomment lines below to download audio files for training\n",
    "\n",
    "#!wget http://www.stephenmclaughlin.net/HILT/audio_corpora/NPR_Fresh_Air_diarized.zip\n",
    "#!unzip NPR_Fresh_Air_diarized.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno -2] Name or service not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-695a445ed535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcsv_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/hipstas/aapb-labels/master/Terry_Gross/Terry_Gross_corrected_SV.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcsv_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_opener\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0m_opener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 422\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPSConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# XXX what error?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -2] Name or service not known>"
     ]
    }
   ],
   "source": [
    "## Loading label data CSV as a list of lists\n",
    "\n",
    "## Random 1-second labels\n",
    "#csv_url = \"https://raw.githubusercontent.com/hipstas/aapb-labels/master/Terry_Gross/Terry_Gross_labels.csv\"\n",
    "\n",
    "## Labels done by hand in Sonic Visualiser\n",
    "csv_url = 'https://raw.githubusercontent.com/hipstas/aapb-labels/master/Terry_Gross/Terry_Gross_corrected_SV.csv'\n",
    "\n",
    "csv_string = urllib2.urlopen(csv_url)\n",
    "\n",
    "train_table = []\n",
    "\n",
    "csv_reader = unicodecsv.reader(csv_string)\n",
    "\n",
    "for row in csv_reader:\n",
    "        train_table.append(row)\n",
    "\n",
    "train_table[:10]+['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0dc102d7a091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Removing header row if present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'Media file basename'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_table' is not defined"
     ]
    }
   ],
   "source": [
    "## Removing header row if present\n",
    "\n",
    "if 'Media file basename' in train_table[0]:\n",
    "    train_table = train_table[1:]\n",
    "\n",
    "random.shuffle(train_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Excerpting WAV clips corresponding to labels\n",
    "\n",
    "training_audio_pathname = \"NPR_Fresh_Air_diarized\"\n",
    "out_dir = '_classes_SV_' + training_audio_pathname\n",
    "\n",
    "\n",
    "for row in train_table:\n",
    "    try:\n",
    "        basename , start, duration, class_name, labeled_by = row  ## Assigning values in row to variables\n",
    "        filename = str(basename + '.mp3')\n",
    "        start = float(start)\n",
    "        end = float(start) + float(duration)\n",
    "        out_pathname = str(os.path.join(out_dir, class_name.replace(' ','_')))\n",
    "        try: \n",
    "            subprocess.call(['mkdir', '-p', out_pathname])\n",
    "        except:\n",
    "            pass\n",
    "        attk.subclip(os.path.join(training_audio_pathname, filename), float(start), end, out_pathname) ## <- attk\n",
    "    except Exception as e: \n",
    "        print(row)\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_pairs(media_path,vowel_time_ranges):\n",
    "    snd = AudioFileClip.AudioFileClip(media_path)\n",
    "    file_duration = attk.duration(media_path)\n",
    "    for pair in vowel_time_ranges:\n",
    "        start, end = pair\n",
    "        start = float(start)\n",
    "        end = float(end)\n",
    "        if end-start >= 0.1:  ## Ignore clips shorter than 0.1 second\n",
    "            basename = media_path.split('/')[-1][:-4]\n",
    "            out_filename = basename+'__'+str(round(start, 4))+'_'+str(round(end, 4))+'.wav'\n",
    "            snd.subclip(start, end).write_audiofile(os.path.join('_vowel_clips',out_filename))\n",
    "\n",
    "\n",
    "def batch_extract_vowels(media_dir):\n",
    "\n",
    "    starting_location = os.getcwd()\n",
    "    \n",
    "    os.chdir(media_dir)\n",
    "\n",
    "    bin_2048_to_sec_constant = 0.046439909297052155\n",
    "    \n",
    "    try: os.mkdir('_vowel_clips')\n",
    "    except: pass\n",
    "\n",
    "    filenames=[item for item in os.listdir('./') if item[-4:].lower() in ('.mp3','.wav','.mp4')]\n",
    "\n",
    "    tic=timeit.default_timer()\n",
    "\n",
    "    for filename in filenames[::-1]:\n",
    "        try:\n",
    "            vowel_bools = attk.get_vowel_segments(filename)\n",
    "\n",
    "            vowel_bin_ranges = attk.labels_to_ranges(vowel_bools, label=True)\n",
    "\n",
    "            vowel_time_ranges = [(s*bin_2048_to_sec_constant, e*bin_2048_to_sec_constant) for s, e in vowel_bin_ranges]\n",
    "            \n",
    "            extract_pairs(filename,vowel_time_ranges)\n",
    "\n",
    "        except: print(\"***** ERROR: \"+filename)\n",
    "\n",
    "    print(\"Time elapsed: \"+str(timeit.default_timer() - tic))\n",
    "\n",
    "    os.chdir(starting_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_SV_NPR_Fresh_Air_diarized')\n",
    "\n",
    "#for class_dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "#    batch_extract_vowels(class_dir_name)\n",
    "\n",
    "batch_extract_vowels('Terry_Gross')\n",
    "#batch_extract_vowels('Background_Speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized')\n",
    "\n",
    "#for class_dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "#    batch_extract_vowels(class_dir_name)\n",
    "\n",
    "batch_extract_vowels('Terry_Gross')\n",
    "batch_extract_vowels('Background_Speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017')\n",
    "\n",
    "#batch_extract_vowels('Female')\n",
    "batch_extract_vowels('Male')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.505573988\n"
     ]
    }
   ],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_SV_NPR_Fresh_Air_diarized/')\n",
    "\n",
    "\n",
    "dir_names = [item for item in os.listdir('./') if os.path.isdir(item)]\n",
    "\n",
    "for dir_name in dir_names:\n",
    "    \n",
    "    os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_SV_NPR_Fresh_Air_diarized/' + dir_name + '/_vowel_clips')\n",
    "    \n",
    "    try: os.mkdir('../_vowel_mfccs_and_deltas')\n",
    "    except: pass\n",
    "    \n",
    "    for filename in [item for item in os.listdir('./') if item.lower()[-4:] == '.wav']:\n",
    "        csv_out_path = '../_vowel_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv'\n",
    "        if not os.path.isfile(csv_out_path):\n",
    "            try:\n",
    "                mfccs = attk.get_mfccs_and_deltas(filename)\n",
    "                with open(csv_out_path, 'w') as fo:\n",
    "                    csv_writer = csv.writer(fo)\n",
    "                    csv_writer.writerows(mfccs)  \n",
    "            except:\n",
    "                \"ERROR on \" + filename\n",
    "\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989500045776\n"
     ]
    }
   ],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized/')\n",
    "\n",
    "dir_names = [item for item in os.listdir('./') if os.path.isdir(item)]\n",
    "\n",
    "for dir_name in dir_names:\n",
    "    \n",
    "    try:\n",
    "        os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized/' + dir_name + '/_vowel_clips')\n",
    "    \n",
    "        try: os.mkdir('../_vowel_mfccs_and_deltas')\n",
    "        except: pass\n",
    "    \n",
    "        csv_out_path = '../_vowel_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv'\n",
    "        if not os.path.isfile(csv_out_path):\n",
    "            try:\n",
    "                mfccs = attk.get_mfccs_and_deltas(filename)\n",
    "                with open(csv_out_path, 'w') as fo:\n",
    "                    csv_writer = csv.writer(fo)\n",
    "                    csv_writer.writerows(mfccs)  \n",
    "            except:\n",
    "                \"ERROR on \" + filename\n",
    "                \n",
    "    except: pass\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217.990756035\n"
     ]
    }
   ],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017')\n",
    "\n",
    "dir_names = [item for item in os.listdir('./') if os.path.isdir(item)]\n",
    "\n",
    "for dir_name in dir_names:\n",
    "    \n",
    "    try:\n",
    "        os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017/' + dir_name + '/_vowel_clips')\n",
    "    \n",
    "        try: os.mkdir('../_vowel_mfccs_and_deltas')\n",
    "        except: pass\n",
    "    \n",
    "        for filename in [item for item in os.listdir('./') if item.lower()[-4:] == '.wav']:\n",
    "            mfccs = attk.get_mfccs_and_deltas(filename)\n",
    "            with open('../_vowel_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv', 'w') as fo:\n",
    "                csv_writer = csv.writer(fo)\n",
    "                csv_writer.writerows(mfccs)  \n",
    "    except: pass\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3824\n",
      "40301\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized/Terry_Gross/_vowel_mfccs_and_deltas')\n",
    "\n",
    "gross_features = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    with open(filename) as fi:\n",
    "        csv_reader = csv.reader(fi)\n",
    "        for row in csv_reader:\n",
    "            gross_features.append([float(item) for item in row])\n",
    "\n",
    "print(len(gross_features))\n",
    "\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_SV_NPR_Fresh_Air_diarized/Terry_Gross/_vowel_mfccs_and_deltas')\n",
    "\n",
    "gross_sv_features = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    with open(filename) as fi:\n",
    "        csv_reader = csv.reader(fi)\n",
    "        for row in csv_reader:\n",
    "            gross_sv_features.append([float(item) for item in row])\n",
    "\n",
    "print(len(gross_sv_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13314\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized/Background_Speaker/_vowel_mfccs_and_deltas')\n",
    "\n",
    "fa_ubm_features = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    with open(filename) as fi:\n",
    "        csv_reader = csv.reader(fi)\n",
    "        for row in csv_reader:\n",
    "            fa_ubm_features.append([float(item) for item in row])\n",
    "\n",
    "print(len(fa_ubm_features))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11531\n",
      "4382\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017/Male/_vowel_mfccs_and_deltas')\n",
    "\n",
    "m_ubm_features = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    with open(filename) as fi:\n",
    "        csv_reader = csv.reader(fi)\n",
    "        for row in csv_reader:\n",
    "            m_ubm_features.append([float(item) for item in row])\n",
    "\n",
    "print(len(m_ubm_features))\n",
    "\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017/Female/_vowel_mfccs_and_deltas')\n",
    "\n",
    "f_ubm_features = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    with open(filename) as fi:\n",
    "        csv_reader = csv.reader(fi)\n",
    "        for row in csv_reader:\n",
    "            f_ubm_features.append([float(item) for item in row])\n",
    "\n",
    "print(len(f_ubm_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3824\n",
      "29227\n"
     ]
    }
   ],
   "source": [
    "## Combining feature sets\n",
    "\n",
    "terry_gross_mfccs = gross_features #+ gross_sv_features\n",
    "ubm_mfccs = fa_ubm_features + m_ubm_features + f_ubm_features\n",
    "\n",
    "#terry_gross_mfccs = terry_gross_mfccs[::-1]\n",
    "#ubm_mfccs = ubm_mfccs[::-1]\n",
    "\n",
    "#random.shuffle(terry_gross_mfccs)\n",
    "#random.shuffle(ubm_mfccs)\n",
    "\n",
    "print(len(terry_gross_mfccs))\n",
    "print(len(ubm_mfccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.3721768856\n"
     ]
    }
   ],
   "source": [
    "## Decision tree\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "X = terry_gross_mfccs[:-len(terry_gross_mfccs)/10] + ubm_mfccs[:-len(ubm_mfccs)/10]\n",
    "y = [0]*len(terry_gross_mfccs[:-len(terry_gross_mfccs)/10]) + [1]*len(ubm_mfccs[:-len(ubm_mfccs)/10])\n",
    "\n",
    "X_test = terry_gross_mfccs[-len(terry_gross_mfccs)/10:] + ubm_mfccs[-len(ubm_mfccs)/10:]\n",
    "y_test = [0]*len(terry_gross_mfccs[-len(terry_gross_mfccs)/10:]) + [1]*len(ubm_mfccs[-len(ubm_mfccs)/10:])\n",
    "\n",
    "classifier = MLPClassifier().fit(X, y)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(classifier,'gross_vowels_et_2048.pkl')\n",
    "classifier=joblib.load('gross_vowels_et_2048.pkl')\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82637628554143983"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3824\n",
      "29227\n"
     ]
    }
   ],
   "source": [
    "## Combining feature sets\n",
    "\n",
    "speaker_1_mfccs = gross_features + gross_sv_features\n",
    "bg_mfccs = fa_ubm_features + m_ubm_features + f_ubm_features\n",
    "\n",
    "#speaker_1_mfccs = terry_gross_mfccs[::-1]\n",
    "#bg_mfccs = ubm_mfccs[::-1]\n",
    "\n",
    "#random.shuffle(speaker_1_mfccs)\n",
    "#random.shuffle(bg_mfccs)\n",
    "\n",
    "print(len(terry_gross_mfccs))\n",
    "print(len(ubm_mfccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145.528022</td>\n",
       "      <td>52.556185</td>\n",
       "      <td>-19.836026</td>\n",
       "      <td>-4.779479</td>\n",
       "      <td>-1.471527</td>\n",
       "      <td>18.713974</td>\n",
       "      <td>-8.128435</td>\n",
       "      <td>-10.357780</td>\n",
       "      <td>-3.947624</td>\n",
       "      <td>1.606438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288286</td>\n",
       "      <td>-0.592404</td>\n",
       "      <td>-1.130820</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.169714</td>\n",
       "      <td>0.092444</td>\n",
       "      <td>-0.516519</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>-0.419400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143.162753</td>\n",
       "      <td>-22.091946</td>\n",
       "      <td>11.111120</td>\n",
       "      <td>-5.802959</td>\n",
       "      <td>-5.327405</td>\n",
       "      <td>4.877378</td>\n",
       "      <td>-13.537851</td>\n",
       "      <td>-2.446800</td>\n",
       "      <td>-15.543847</td>\n",
       "      <td>16.445061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640322</td>\n",
       "      <td>0.077595</td>\n",
       "      <td>-0.315508</td>\n",
       "      <td>0.754390</td>\n",
       "      <td>-0.619043</td>\n",
       "      <td>-0.025048</td>\n",
       "      <td>-1.225697</td>\n",
       "      <td>0.418339</td>\n",
       "      <td>0.236048</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.469516</td>\n",
       "      <td>40.253117</td>\n",
       "      <td>75.463766</td>\n",
       "      <td>2.474142</td>\n",
       "      <td>16.307388</td>\n",
       "      <td>6.242862</td>\n",
       "      <td>-18.638111</td>\n",
       "      <td>-12.341957</td>\n",
       "      <td>2.357186</td>\n",
       "      <td>-12.481317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623618</td>\n",
       "      <td>0.571974</td>\n",
       "      <td>-0.249141</td>\n",
       "      <td>-0.044193</td>\n",
       "      <td>0.020489</td>\n",
       "      <td>0.339805</td>\n",
       "      <td>-0.032752</td>\n",
       "      <td>-0.429253</td>\n",
       "      <td>0.275497</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179.407453</td>\n",
       "      <td>-12.910994</td>\n",
       "      <td>5.877851</td>\n",
       "      <td>-53.849837</td>\n",
       "      <td>-3.449369</td>\n",
       "      <td>14.889508</td>\n",
       "      <td>10.798665</td>\n",
       "      <td>-36.533244</td>\n",
       "      <td>-7.673434</td>\n",
       "      <td>-5.605504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>-0.165666</td>\n",
       "      <td>0.107095</td>\n",
       "      <td>0.232014</td>\n",
       "      <td>-0.385006</td>\n",
       "      <td>0.280536</td>\n",
       "      <td>-0.905222</td>\n",
       "      <td>0.602623</td>\n",
       "      <td>0.441850</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158.184824</td>\n",
       "      <td>68.084102</td>\n",
       "      <td>31.297796</td>\n",
       "      <td>36.776827</td>\n",
       "      <td>28.833738</td>\n",
       "      <td>-10.733498</td>\n",
       "      <td>11.227472</td>\n",
       "      <td>-6.689189</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>16.571019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621358</td>\n",
       "      <td>-1.651220</td>\n",
       "      <td>0.495750</td>\n",
       "      <td>-0.225871</td>\n",
       "      <td>0.120457</td>\n",
       "      <td>-0.323987</td>\n",
       "      <td>-0.776101</td>\n",
       "      <td>0.168192</td>\n",
       "      <td>-0.311773</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5  \\\n",
       "0  145.528022  52.556185 -19.836026  -4.779479  -1.471527  18.713974   \n",
       "1  143.162753 -22.091946  11.111120  -5.802959  -5.327405   4.877378   \n",
       "2   -0.469516  40.253117  75.463766   2.474142  16.307388   6.242862   \n",
       "3  179.407453 -12.910994   5.877851 -53.849837  -3.449369  14.889508   \n",
       "4  158.184824  68.084102  31.297796  36.776827  28.833738 -10.733498   \n",
       "\n",
       "           6          7          8          9     ...             29  \\\n",
       "0  -8.128435 -10.357780  -3.947624   1.606438     ...       0.288286   \n",
       "1 -13.537851  -2.446800 -15.543847  16.445061     ...       0.640322   \n",
       "2 -18.638111 -12.341957   2.357186 -12.481317     ...       0.623618   \n",
       "3  10.798665 -36.533244  -7.673434  -5.605504     ...       0.554404   \n",
       "4  11.227472  -6.689189   0.528000  16.571019     ...      -1.621358   \n",
       "\n",
       "         30        31        32        33        34        35        36  \\\n",
       "0 -0.592404 -1.130820  0.004470  0.169714  0.092444 -0.516519  0.004081   \n",
       "1  0.077595 -0.315508  0.754390 -0.619043 -0.025048 -1.225697  0.418339   \n",
       "2  0.571974 -0.249141 -0.044193  0.020489  0.339805 -0.032752 -0.429253   \n",
       "3 -0.165666  0.107095  0.232014 -0.385006  0.280536 -0.905222  0.602623   \n",
       "4 -1.651220  0.495750 -0.225871  0.120457 -0.323987 -0.776101  0.168192   \n",
       "\n",
       "         37  Class Label  \n",
       "0 -0.419400          1.0  \n",
       "1  0.236048          1.0  \n",
       "2  0.275497          1.0  \n",
       "3  0.441850          1.0  \n",
       "4 -0.311773          1.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### KERAS\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "speaker_1_mfccs_df = pd.DataFrame(speaker_1_mfccs[:-500])\n",
    "\n",
    "speaker_1_mfccs_df['Class Label'] = 1.0   ## Terry Gross\n",
    "\n",
    "\n",
    "bg_mfccs_df = pd.DataFrame(bg_mfccs[:-500])\n",
    "\n",
    "bg_mfccs_df['Class Label'] = 0.0    ## Background speaker\n",
    "\n",
    "\n",
    "training_data_df = pd.concat([speaker_1_mfccs_df, bg_mfccs_df])\n",
    "\n",
    "training_data_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speaker_1_mfccs_df_test = pd.DataFrame(speaker_1_mfccs[-500:])\n",
    "speaker_1_mfccs_df_test['Class Label'] = 1.0   ## Terry Gross\n",
    "\n",
    "bg_mfccs_df_test = pd.DataFrame(bg_mfccs[-500:])\n",
    "bg_mfccs_df_test['Class Label'] = 0.0    ## Background speaker\n",
    "\n",
    "test_data_df = pd.concat([speaker_1_mfccs_df_test, bg_mfccs_df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>Class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.542788</td>\n",
       "      <td>0.387842</td>\n",
       "      <td>0.588833</td>\n",
       "      <td>0.542590</td>\n",
       "      <td>0.455971</td>\n",
       "      <td>0.483816</td>\n",
       "      <td>0.634891</td>\n",
       "      <td>0.476033</td>\n",
       "      <td>0.479879</td>\n",
       "      <td>0.499572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475239</td>\n",
       "      <td>0.444128</td>\n",
       "      <td>0.653842</td>\n",
       "      <td>0.510107</td>\n",
       "      <td>0.412542</td>\n",
       "      <td>0.415514</td>\n",
       "      <td>0.545748</td>\n",
       "      <td>0.527017</td>\n",
       "      <td>0.622477</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.620554</td>\n",
       "      <td>0.427259</td>\n",
       "      <td>0.424873</td>\n",
       "      <td>0.575730</td>\n",
       "      <td>0.487262</td>\n",
       "      <td>0.569304</td>\n",
       "      <td>0.514076</td>\n",
       "      <td>0.518479</td>\n",
       "      <td>0.565739</td>\n",
       "      <td>0.627275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448298</td>\n",
       "      <td>0.498846</td>\n",
       "      <td>0.399751</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.367423</td>\n",
       "      <td>0.331029</td>\n",
       "      <td>0.326291</td>\n",
       "      <td>0.547375</td>\n",
       "      <td>0.461277</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801378</td>\n",
       "      <td>0.412346</td>\n",
       "      <td>0.540283</td>\n",
       "      <td>0.515692</td>\n",
       "      <td>0.536305</td>\n",
       "      <td>0.439811</td>\n",
       "      <td>0.429129</td>\n",
       "      <td>0.363124</td>\n",
       "      <td>0.427275</td>\n",
       "      <td>0.480368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455441</td>\n",
       "      <td>0.494850</td>\n",
       "      <td>0.400423</td>\n",
       "      <td>0.384490</td>\n",
       "      <td>0.353950</td>\n",
       "      <td>0.322277</td>\n",
       "      <td>0.330851</td>\n",
       "      <td>0.526404</td>\n",
       "      <td>0.431842</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.606114</td>\n",
       "      <td>0.377198</td>\n",
       "      <td>0.657624</td>\n",
       "      <td>0.568292</td>\n",
       "      <td>0.524360</td>\n",
       "      <td>0.541956</td>\n",
       "      <td>0.714307</td>\n",
       "      <td>0.526312</td>\n",
       "      <td>0.489528</td>\n",
       "      <td>0.524479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486767</td>\n",
       "      <td>0.339382</td>\n",
       "      <td>0.343371</td>\n",
       "      <td>0.113690</td>\n",
       "      <td>0.433394</td>\n",
       "      <td>0.423659</td>\n",
       "      <td>0.412654</td>\n",
       "      <td>0.621854</td>\n",
       "      <td>0.537593</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.702619</td>\n",
       "      <td>0.259012</td>\n",
       "      <td>0.490942</td>\n",
       "      <td>0.535733</td>\n",
       "      <td>0.428951</td>\n",
       "      <td>0.327187</td>\n",
       "      <td>0.439968</td>\n",
       "      <td>0.450061</td>\n",
       "      <td>0.504347</td>\n",
       "      <td>0.476029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505922</td>\n",
       "      <td>0.300177</td>\n",
       "      <td>0.322718</td>\n",
       "      <td>0.093326</td>\n",
       "      <td>0.425267</td>\n",
       "      <td>0.402008</td>\n",
       "      <td>0.392605</td>\n",
       "      <td>0.599755</td>\n",
       "      <td>0.541202</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.542788  0.387842  0.588833  0.542590  0.455971  0.483816  0.634891   \n",
       "1  0.620554  0.427259  0.424873  0.575730  0.487262  0.569304  0.514076   \n",
       "2  0.801378  0.412346  0.540283  0.515692  0.536305  0.439811  0.429129   \n",
       "3  0.606114  0.377198  0.657624  0.568292  0.524360  0.541956  0.714307   \n",
       "4  0.702619  0.259012  0.490942  0.535733  0.428951  0.327187  0.439968   \n",
       "\n",
       "          7         8         9     ...             29        30        31  \\\n",
       "0  0.476033  0.479879  0.499572     ...       0.475239  0.444128  0.653842   \n",
       "1  0.518479  0.565739  0.627275     ...       0.448298  0.498846  0.399751   \n",
       "2  0.363124  0.427275  0.480368     ...       0.455441  0.494850  0.400423   \n",
       "3  0.526312  0.489528  0.524479     ...       0.486767  0.339382  0.343371   \n",
       "4  0.450061  0.504347  0.476029     ...       0.505922  0.300177  0.322718   \n",
       "\n",
       "         32        33        34        35        36        37  Class Label  \n",
       "0  0.510107  0.412542  0.415514  0.545748  0.527017  0.622477          1.0  \n",
       "1  0.400400  0.367423  0.331029  0.326291  0.547375  0.461277          1.0  \n",
       "2  0.384490  0.353950  0.322277  0.330851  0.526404  0.431842          1.0  \n",
       "3  0.113690  0.433394  0.423659  0.412654  0.621854  0.537593          1.0  \n",
       "4  0.093326  0.425267  0.402008  0.392605  0.599755  0.541202          1.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "scaled_training = scaler.fit_transform(training_data_df)\n",
    "scaled_testing = scaler.transform(test_data_df)\n",
    "\n",
    "# Print out the adjustment that the scaler applied to the total_earnings column of data\n",
    "#######print(\"Note: total_earnings values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[8], scaler.min_[8]))\n",
    "\n",
    "# Create new pandas DataFrame objects from the scaled data\n",
    "scaled_training_df = pd.DataFrame(scaled_training, columns=training_data_df.columns.values)\n",
    "scaled_testing_df = pd.DataFrame(scaled_testing, columns=test_data_df.columns.values)\n",
    "\n",
    "scaled_testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save scaled data dataframes to new CSV files\n",
    "scaled_training_df.to_csv(\"terry_gross_vs_ubm_train_scaled.csv\", index=False)\n",
    "scaled_testing_df.to_csv(\"terry_gross_vs_ubm_test_scaled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33203291893\n"
     ]
    }
   ],
   "source": [
    "tic=timeit.default_timer()\n",
    "\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "training_data_df = pd.read_csv(\"terry_gross_vs_ubm_train_scaled.csv\")\n",
    "\n",
    "X = training_data_df.drop('Class Label', axis=1).values\n",
    "Y = training_data_df[['Class Label']].values\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=38, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(42, activation='relu'))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6s - loss: 0.1844\n",
      "Epoch 2/50\n",
      "5s - loss: 0.1593\n",
      "Epoch 3/50\n",
      "5s - loss: 0.1512\n",
      "Epoch 4/50\n",
      "5s - loss: 0.1462\n",
      "Epoch 5/50\n",
      "5s - loss: 0.1426\n",
      "Epoch 6/50\n",
      "5s - loss: 0.1390\n",
      "Epoch 7/50\n",
      "5s - loss: 0.1366\n",
      "Epoch 8/50\n",
      "5s - loss: 0.1341\n",
      "Epoch 9/50\n",
      "5s - loss: 0.1323\n",
      "Epoch 10/50\n",
      "5s - loss: 0.1302\n",
      "Epoch 11/50\n",
      "5s - loss: 0.1276\n",
      "Epoch 12/50\n",
      "5s - loss: 0.1262\n",
      "Epoch 13/50\n",
      "6s - loss: 0.1249\n",
      "Epoch 14/50\n",
      "6s - loss: 0.1231\n",
      "Epoch 15/50\n",
      "6s - loss: 0.1220\n",
      "Epoch 16/50\n",
      "6s - loss: 0.1209\n",
      "Epoch 17/50\n",
      "6s - loss: 0.1197\n",
      "Epoch 18/50\n",
      "7s - loss: 0.1182\n",
      "Epoch 19/50\n",
      "7s - loss: 0.1172\n",
      "Epoch 20/50\n",
      "8s - loss: 0.1156\n",
      "Epoch 21/50\n",
      "6s - loss: 0.1151\n",
      "Epoch 22/50\n",
      "5s - loss: 0.1145\n",
      "Epoch 23/50\n",
      "5s - loss: 0.1130\n",
      "Epoch 24/50\n",
      "8s - loss: 0.1122\n",
      "Epoch 25/50\n",
      "6s - loss: 0.1106\n",
      "Epoch 26/50\n",
      "7s - loss: 0.1102\n",
      "Epoch 27/50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Load the separate test data set\n",
    "test_data_df = pd.read_csv(\"terry_gross_vs_ubm_test_scaled.csv\")\n",
    "\n",
    "X_test = test_data_df.drop('Class Label', axis=1).values\n",
    "Y_test = test_data_df[['Class Label']].values\n",
    "\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: \" + str(test_error_rate))\n",
    "\n",
    "# Save the model to disk\n",
    "model.save(\"trained_model.h5\")\n",
    "print(\"Model saved to disk.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs=get_mfccs_and_deltas(clip_pathname)\n",
    "    results = random_forest.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = get_vowel_segments(clip_pathname)[::2]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading pre-trained model\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#random_forest=joblib.load('pesca_vowels_random_forest_2048.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs=get_mfccs_and_deltas(clip_pathname)\n",
    "    results = classifier.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = get_vowel_segments(clip_pathname)[::2]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "filename = random.choice(os.listdir('unseen/'))\n",
    "test_pathname = 'unseen/'+filename\n",
    "test_mfccs=attk.get_mfccs_and_deltas(test_pathname)\n",
    "\n",
    "print(test_pathname)\n",
    "\n",
    "results = classifier.predict(test_mfccs)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = get_vowel_segments(test_pathname)[::2]\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if vowel_bools[i]==True:\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(test_pathname))\n",
    "\n",
    "\n",
    "print(\"All: \"+str(np.mean(results)))\n",
    "print(\"Vowels only: \"+str(np.mean(vowel_results)))\n",
    "\n",
    "#print(\"Time elapsed: \"+str(timeit.default_timer() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(get_vowel_segments(test_pathname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!du /tmp/temp_clip.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Classifying a long audio file\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "\n",
    "media_path = \"/sharedfolder/fa_eval/FA_Author_Tom_Perrotta.mp3\"\n",
    "\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications=[]\n",
    "\n",
    "for i in range(int(attk.duration(media_path))):\n",
    "    try:\n",
    "        snd.subclip(i,i+1).write_audiofile('/tmp/temp_clip.wav')\n",
    "        classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "    except: print('missed one')\n",
    "\n",
    "classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing classification output to CSV\n",
    "\n",
    "counter=0\n",
    "\n",
    "class_0_secs=[]\n",
    "class_1_secs=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "for classification in attk.smooth(np.array(classifications)):\n",
    "    if classification < 0.34:\n",
    "        class_0_secs.append(i)\n",
    "    if classification > 0.38:\n",
    "        class_1_secs.append(i)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "counter=0\n",
    "\n",
    "csv_path=media_path[:-4]+'_extratrees2048_labels.csv'\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    for pair in seconds_list_to_ranges(class_0_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Terry Gross\\n')\n",
    "    for pair in seconds_list_to_ranges(class_1_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Background\\n')\n",
    "\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
