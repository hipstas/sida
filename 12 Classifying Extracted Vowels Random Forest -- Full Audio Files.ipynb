{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from IPython.display import display, Audio\n",
    "import timeit\n",
    "import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "import subprocess\n",
    "\n",
    "os.chdir('/home/sharedfolder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (7, 9), (34, 34), (99, 102), (199, 199)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mfccs(wav_pathname):\n",
    "    sample_array, sample_rate = librosa.load(wav_pathname)\n",
    "    mfcc_frames = librosa.feature.mfcc(sample_array, sample_rate, hop_length=512, n_mfcc=13).T\n",
    "    mfcc_frames_sans_0th = [frame_values[1:] for frame_values in mfcc_frames]\n",
    "    return mfcc_frames_sans_0th\n",
    "\n",
    "def get_mfccs_and_deltas(wav_pathname):\n",
    "    sample_array, sample_rate = librosa.load(wav_pathname)\n",
    "    mfcc = librosa.feature.mfcc(sample_array, sample_rate, hop_length=512, n_mfcc=13)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    mfcc=mfcc.T     ### Transposing tables\n",
    "    delta=delta.T   ## (We can instead set the axis above to do this without the extra step)\n",
    "    delta2=delta2.T\n",
    "    mfcc_sans_0th = [frame_values[1:] for frame_values in mfcc]\n",
    "    all_features=[]\n",
    "    for i in range(len(mfcc)):\n",
    "        all_features.append(list(mfcc_sans_0th[i])+list(delta[i])+list(delta2[i]))\n",
    "    return all_features\n",
    "\n",
    "def get_vowel_segments(media_path):\n",
    "    downsample = 1\n",
    "    samplerate = 44100 // downsample\n",
    "\n",
    "    win_s = 2048 // downsample # fft size\n",
    "    hop_s = 512  // downsample # hop size\n",
    "\n",
    "    s = source(media_path, samplerate, hop_s)\n",
    "    samplerate = s.samplerate\n",
    "\n",
    "    tolerance = 0.6\n",
    "\n",
    "    pitch_o = pitch(\"yin\", win_s, hop_s, samplerate)\n",
    "    pitch_o.set_unit(\"Hz\")\n",
    "    pitch_o.set_tolerance(tolerance)\n",
    "\n",
    "    pitches = []\n",
    "    confidences = []\n",
    "\n",
    "    # total number of frames read\n",
    "    total_frames = 0\n",
    "    samples=[]\n",
    "    pitches=[]\n",
    "    while True:\n",
    "        samples, read = s()\n",
    "        pitch_ = pitch_o(samples)[0]\n",
    "        #pitch = int(round(pitch))\n",
    "        confidence = pitch_o.get_confidence()\n",
    "        #print(\"%f %f %f\" % (total_frames / float(samplerate), pitch, confidence))\n",
    "        pitches += [pitch_]\n",
    "        confidences += [confidence]\n",
    "        total_frames += read\n",
    "        if read < hop_s: break\n",
    "\n",
    "    pitches = np.array(pitches)\n",
    "    confidences = np.array(confidences)\n",
    "\n",
    "    cleaned_pitches = ma.masked_where(confidences < tolerance, pitches)\n",
    "    cleaned_pitches = ma.masked_where(cleaned_pitches > 1000, cleaned_pitches)\n",
    "    return list(np.logical_not(cleaned_pitches.mask))\n",
    "\n",
    "\n",
    "def media_duration(media_path):\n",
    "    return float(subprocess.check_output(['ffprobe', '-v', 'quiet', '-of', 'csv=p=0', '-show_entries', 'format=duration', media_path]).strip())\n",
    "\n",
    "\n",
    "def smooth(x,window_len=10,window='hanning'):\n",
    "        if x.ndim != 1:\n",
    "                raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "        if x.size < window_len:\n",
    "                raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "        if window_len<3:\n",
    "                return x\n",
    "        if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "        s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:  \n",
    "                w=eval('np.'+window+'(window_len)')\n",
    "        y=np.convolve(w/w.sum(),s,mode='same')\n",
    "        return y[window_len:-window_len+1]\n",
    "\n",
    "\n",
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs=get_mfccs_and_deltas(clip_pathname)\n",
    "    results = random_forest.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = get_vowel_segments(clip_pathname)[::2]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only\n",
    "\n",
    "\n",
    "def seconds_list_to_ranges(seconds_list): \n",
    "    ranges = []                \n",
    "    for k, g in groupby(enumerate(seconds_list), lambda (i,x):i-x):\n",
    "        group = map(itemgetter(1), g)\n",
    "        ranges.append((group[0], group[-1]))\n",
    "    return ranges\n",
    "\n",
    "seconds_list_to_ranges([1,2,3,7,8,9,34,99,100,101,102,199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "pesca_mfccs = []\n",
    "\n",
    "for filename in os.listdir('3_training_classes/Mike_Pesca/_vowel_clips'):\n",
    "    if '.wav' in filename:\n",
    "        pesca_mfccs += get_mfccs_and_deltas('3_training_classes/Mike_Pesca/_vowel_clips/'+filename)\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n",
    "bg_male_mfccs = []\n",
    "\n",
    "for filename in os.listdir('3_training_classes/Background_male/_vowel_clips'):\n",
    "    if '.wav' in filename:\n",
    "        bg_male_mfccs += get_mfccs_and_deltas('3_training_classes/Background_male/_vowel_clips/'+filename)\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "##\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "bg_female_mfccs = []\n",
    "\n",
    "for filename in os.listdir('3_training_classes/Background_female/_vowel_clips'):\n",
    "    if '.wav' in filename:\n",
    "        bg_female_mfccs += get_mfccs_and_deltas('3_training_classes/Background_female/_vowel_clips/'+filename)\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pesca_mfccs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-07df1801a236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpesca_mfccs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbg_male_mfccs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbg_female_mfccs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpesca_mfccs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_male_mfccs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_female_mfccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pesca_mfccs' is not defined"
     ]
    }
   ],
   "source": [
    "## Decision tree\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "X = pesca_mfccs + bg_male_mfccs + bg_female_mfccs\n",
    "y = [0]*len(pesca_mfccs) + [1]*len(bg_male_mfccs) + [1]*len(bg_female_mfccs)\n",
    "\n",
    "random_forest = RandomForestClassifier().fit(X, y)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(random_forest,'pesca_vowels_random_forest.pkl')\n",
    "random_forest=joblib.load('pesca_vowels_random_forest.pkl')\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading pre-trained model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest=joblib.load('pesca_vowels_random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Classifying a long audio file\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "\n",
    "media_path = \"/home/sharedfolder/3_training_classes/unseen_full_episodes/SM1559496342.mp3\"\n",
    "\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications=[]\n",
    "\n",
    "for i in range(int(media_duration(media_path))):\n",
    "    snd.subclip(i,i+1).write_audiofile('/tmp/temp_clip.wav')\n",
    "    classifications.append(classify_clip('/tmp/temp_clip.wav'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811.81339407\n"
     ]
    }
   ],
   "source": [
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing classification output to CSV\n",
    "\n",
    "counter=0\n",
    "\n",
    "class_0_secs=[]\n",
    "class_1_secs=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "for classification in smooth(np.array(classifications)):\n",
    "    if classification < 0.25:\n",
    "        class_0_secs.append(i)\n",
    "    if classification > 0.3:\n",
    "        class_1_secs.append(i)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "counter=0\n",
    "\n",
    "csv_path=media_path[:-4]+'_random_forest_labels.csv'\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    for pair in seconds_list_to_ranges(class_0_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Pesca\\n')\n",
    "    for pair in seconds_list_to_ranges(class_1_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Background\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
