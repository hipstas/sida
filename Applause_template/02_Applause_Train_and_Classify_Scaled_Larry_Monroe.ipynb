{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "speaker_list = ['Applause', 'Non-Applause']\n",
    "\n",
    "speaker_0_label, speaker_1_label = speaker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71168\t/sharedfolder/sida_classifier/_classes_Applause/applause/_mfccs_and_deltas\r\n",
      "281856\t/sharedfolder/sida_classifier/_classes_Applause/applause/\r\n"
     ]
    }
   ],
   "source": [
    "!du /sharedfolder/sida_classifier/_classes_Applause/applause/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sharedfolder/sida_classifier/_classes_Applause/applause/_mfccs_and_deltas/._Belladonna_Segue_Zinc_10-19-13__5785.0_5788.0.mfcc.csv\n",
      "line contains NULL byte\n",
      "/sharedfolder/sida_classifier/_classes_Applause/applause/_mfccs_and_deltas/._Ashbery-John_01_Introduction_David-Schubert_Other-Traditions_Charles-Eliot-Norton-Lecture-Series_Harvard_1990__157.0_160.0.mfcc.csv\n",
      "line contains NULL byte\n",
      "9050\n",
      "19175\n"
     ]
    }
   ],
   "source": [
    "## Load saved features\n",
    "\n",
    "def load_features(dir_path):\n",
    "    features = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        try:\n",
    "            with open(os.path.join(dir_path, filename)) as fi:\n",
    "                csv_reader = csv.reader(fi)\n",
    "                for row in csv_reader:\n",
    "                    features.append([float(item) for item in row])\n",
    "        except Exception as e: \n",
    "            print(os.path.join(dir_path, filename))\n",
    "            print(e)\n",
    "    return features\n",
    "\n",
    "speaker_0_features = load_features('/sharedfolder/sida_classifier/_classes_Applause/applause/_mfccs_and_deltas')\n",
    "print(len(speaker_0_features))\n",
    "\n",
    "speaker_1_features = load_features('/sharedfolder/sida_classifier/_classes_Applause/non_applause/_mfccs_and_deltas')\n",
    "print(len(speaker_1_features))\n",
    "\n",
    "\n",
    "min_length = np.min([len(speaker_0_features), len(speaker_1_features)])\n",
    "#speaker_0_features = random.sample(speaker_0_features, min_length)\n",
    "#speaker_1_features = random.sample(speaker_1_features, min_length)\n",
    "\n",
    "\n",
    "#aapb_ubm_male_features = load_features('/sharedfolder/sida_classifier/AAPB_male_vowel_mfccs_and_deltas_100-5K_Hz')\n",
    "#print(len(aapb_ubm_male_features))\n",
    "\n",
    "#aapb_ubm_female_features = load_features('/sharedfolder/sida_classifier/AAPB_female_vowel_mfccs_and_deltas_100-5K_Hz')\n",
    "#print(len(aapb_ubm_female_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136.49686600481718, -30.074039485079535, 8.60019119405769, 16.52587775019098, 5.9449443978918755, -0.6638242508420991, -18.359454390465565, -14.735571423388855, -2.090056269988988, 3.3472845679880523, -2.6381934978170998, -2.7265441363862113, -2.8846134807288264, -1.7423181956775542, 8.027486187803722, 1.0600991232973298, -5.2604663957383115, 2.2959047638897117, 7.226201459603564, 1.3063174355893503, 2.6415441363955434, 1.8608157703606896, -3.8509774336929095, -11.83327006535713, -7.152783894002935, -8.487607708434375, -16.943803238628828, -12.06850841269803, -11.727580307083826, -3.6137684461582253, -0.44834861412607196, 2.2687637762136665, -0.6039057262090552, 0.43060798209378515, 0.981116253206451, -1.5694155809476085, -1.3506685923811785, -0.06353341033671389, 0.17392538797233312, -0.9430262989846061, -1.4304612056848123, -0.7797333697803576, -0.1530292023528912, -0.31957752579914056, -0.3259772975062665, -0.1490276430440528, 0.2848487683133042, 0.4169231260365275, 0.6707003997810436, 0.5854847498959665, -0.499125261270029, -0.997240076610678, 0.03335800200202027, -0.15877597926302703, -0.44447939680718096, -1.246633587861555, -0.8935737374270334, -0.6099406406659088, -0.6558177730691718, -0.6065801215564945, -0.07032313600355747, 0.6712295101955311, -0.06168360850729763, -0.4131615042527321, -0.016038551656967756, -0.3109950281700373, -0.07489385374208522, 0.18256172424666714, 0.07763875774923888, -0.003939178320093981, -0.20762167718429564, -0.06909078117818548, 0.055682932839970535, -0.0043604565649523475, -0.210613167136926, -0.2072663940275788, 0.2447217348925479, 0.10644722375456257, -0.09423928899531417, -0.12229886307375896, -0.19782379963773292, -0.22577004875487805, 0.17072653054627093, 0.32066568174081767, -0.0974487126262149, -0.4960060848129964, -0.45183174073937293, -0.19570961550188784, -0.05489245960310849]\n"
     ]
    }
   ],
   "source": [
    "## Printing MFCCs and deltas for a single frame\n",
    "\n",
    "print(random.choice(speaker_1_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining feature sets\n",
    "\n",
    "#speaker_1_features = speaker_1_features\n",
    "#male_ubm_features = program_ubm_male_features +  aapb_ubm_male_features \n",
    "#female_ubm_features = program_ubm_female_features + aapb_ubm_female_features\n",
    "\n",
    "#print(len(speaker_1_features))\n",
    "#print(len(male_ubm_features))\n",
    "#print(len(female_ubm_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and multi-layer perceptron model with 9/10 of training data and evaluating performance on remaining 1/10\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "import random\n",
    "#random.shuffle(speaker_0_features)\n",
    "#random.shuffle(speaker_1_features)\n",
    "#random.shuffle(speaker_2_features)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = speaker_0_features[:-len(speaker_0_features)/10] + speaker_1_features[:-len(speaker_1_features)/10]\n",
    "y = [1]*len(speaker_0_features[:-len(speaker_0_features)/10]) + [0]*len(speaker_1_features[:-len(speaker_1_features)/10])\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y)\n",
    "\n",
    "X_test = speaker_0_features[-len(speaker_0_features)/10:] + speaker_1_features[-len(speaker_1_features)/10:]\n",
    "y_test = [1]*len(speaker_0_features[-len(speaker_0_features)/10:]) + [0]*len(speaker_1_features[-len(speaker_1_features)/10:]) \n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = MLPClassifier(max_iter = 2000, random_state = 9, \\\n",
    "                          hidden_layer_sizes = (100, 100), solver = 'adam', \\\n",
    "                          activation = 'relu').fit(X_train_scaled, y_train)\n",
    "\n",
    "print(classifier.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applause_mlpc_4096_100-16K_scaled_.pkl\n"
     ]
    }
   ],
   "source": [
    "## Training and saving an MLP model with all training data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = speaker_0_features + speaker_1_features\n",
    "y = [0]*len(speaker_0_features) + [1]*len(speaker_1_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "#classifier = MLPClassifier().fit(X_scaled, y)\n",
    "\n",
    "classifier = MLPClassifier(max_iter = 2000, random_state = 9, \\\n",
    "                          hidden_layer_sizes = (100, 100), solver = 'adam', \\\n",
    "                          activation = 'relu').fit(X_scaled, y)\n",
    "\n",
    "trained_model_filename = 'Applause' + '_mlpc_4096_100-16K_scaled_.pkl'\n",
    "print(trained_model_filename)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(classifier, trained_model_filename)\n",
    "joblib.dump(scaler, trained_model_filename.replace('.pkl', '.scaler'))\n",
    "classifier = joblib.load(trained_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.mixture import GaussianMixture\n",
    "\n",
    "#gmm_classifier = GaussianMixture(n_components=3, covariance_type='diag', max_iter=3000).fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#### Start here to load pre-trained model ####\n",
    "##############################################\n",
    "\n",
    "#trained_model_filename = 'mbmbam' + '_vowels_mlpc_4096_100-5K_scaled.pkl'\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier')\n",
    "classifier = joblib.load('Applause_mlpc_4096_100-16K_scaled_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "from pandas.tools.plotting import parallel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=2) #2-dimensional LDA\n",
    "lda_transformed = pd.DataFrame(lda.fit_transform(X_scaled, y))\n",
    "lda_transformed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_transformed['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 mfccs, 4096\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Applause', c='red', alpha=0.2)\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Non_Applause', c='blue', alpha=0.2)\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 mfccs, 2048\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Justin', c='red', alpha=0.1)\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Griffin', c='blue', alpha=0.1)\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==2][0], lda_transformed[lda_transformed['y']==2][1], label='Travis', c='green', alpha=0.1)\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 mfccs, 2048\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Justin', c='red')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Griffin', c='blue')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==2][0], lda_transformed[lda_transformed['y']==2][1], label='Travis', c='green')\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Old\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Justin', c='red')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Griffin', c='blue')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==2][0], lda_transformed[lda_transformed['y']==2][1], label='Travis', c='green')\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "## Download unseen audio and split into 3-second WAV clips for testing\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "try: os.mkdir('test_clips/')\n",
    "except: pass\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/test_clips/')\n",
    "\n",
    "wav_filename = \"LM_03_John-Prine_1976-06-13_CAS_A_SRM.wav\"\n",
    "\n",
    "\n",
    "#subprocess.call(['wget', '-N', mp3_url])\n",
    "\n",
    "#subprocess.call(['ffmpeg', '-i', mp3_filename, wav_filename])\n",
    "\n",
    "subprocess.call(['ffmpeg', '-i', wav_filename, '-f', 'segment', '-segment_time', '3',  wav_filename[:-4] + '_3_sec_%04d.wav'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_class(class_ids):\n",
    "    mode_id = int(list(scipy.stats.mode(class_ids))[0][0])\n",
    "    mode_id_percentage = float(float(class_ids.count(mode_id))/len(class_ids))\n",
    "    return (mode_id, mode_id_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "#### Repeat this cell several times to help choose a classifier threshold value.\n",
    "\n",
    "import scipy\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/test_clips/')\n",
    "\n",
    "wav_pathname = os.path.abspath(random.choice([item for item in os.listdir('./') if '3_sec' in item]))\n",
    "\n",
    "test_features = np.array(attk.get_mfccs_and_deltas(wav_pathname, n_mfcc=30, n_fft=8192))\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "print(wav_pathname)\n",
    "\n",
    "results = classifier.predict(test_features)  ## Predicting new observation\n",
    "results_proba = classifier.predict_proba(test_features)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "print([round(max(item), 4) for item in list(results_proba)])\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = attk.get_vowel_segments(wav_pathname, n_fft=8192)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if True:                                 #vowel_bools[i]==\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(wav_pathname))\n",
    "\n",
    "print(\"MODE: \" + str(list(scipy.stats.mode(results))[0][0])) \n",
    "print(\"MODE vowels only: \" + str(list(scipy.stats.mode(vowel_results))[0][0])) ## Vowels only\n",
    "#print(\"All samples: \"+str(np.mean(results)))\n",
    "#print(\"Vowels only: \"+str(np.mean(vowel_results)))\n",
    "\n",
    "mode_id, mode_id_percentage = most_common_class(vowel_results)\n",
    "top_label = speaker_list[mode_id]\n",
    "\n",
    "print('')\n",
    "print(\"Speaker: \" + str(top_label))\n",
    "print(\"Confidence: \" + str(mode_id_percentage))\n",
    "\n",
    "print('')\n",
    "\n",
    "print(str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "#### Repeat this cell several times to help choose a classifier threshold value.\n",
    "\n",
    "import scipy\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/test_clips/')\n",
    "\n",
    "#wav_pathname = os.path.abspath(random.choice([item for item in os.listdir('./') if '3_sec' in item]))\n",
    "\n",
    "#test_features = np.array(attk.get_mfccs_and_deltas(wav_pathname))\n",
    "#test_features = scaler.transform(test_features)\n",
    "\n",
    "print(wav_pathname)\n",
    "\n",
    "results = classifier.predict(test_features)  ## Predicting new observation\n",
    "results_proba = classifier.predict_proba(test_features)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "print([round(max(item), 4) for item in list(results_proba)])\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = attk.get_vowel_segments(wav_pathname, n_fft=4096)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if True:  #### vowel_bools[i]==\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(wav_pathname))\n",
    "\n",
    "print(\"MODE: \" + str(list(scipy.stats.mode(results))[0][0])) \n",
    "print(\"MODE vowels only: \" + str(list(scipy.stats.mode(vowel_results))[0][0])) ## Vowels only\n",
    "#print(\"All samples: \"+str(np.mean(results)))\n",
    "#print(\"Vowels only: \"+str(np.mean(vowel_results)))\n",
    "\n",
    "mode_id, mode_id_percentage = most_common_class(vowel_results)\n",
    "top_label = speaker_list[mode_id]\n",
    "\n",
    "print('')\n",
    "print(\"Speaker: \" + str(top_label))\n",
    "print(\"Confidence: \" + str(mode_id_percentage))\n",
    "\n",
    "print('')\n",
    "\n",
    "print(str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that classifies vowel segments only and returns \n",
    "## average output for the full clip\n",
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs = np.array(attk.get_mfccs_and_deltas(clip_pathname, n_mfcc=30, n_fft=8192))\n",
    "    mfccs = scaler.transform(mfccs)\n",
    "    results = list(classifier.predict(mfccs))  ## Predicting new observation\n",
    "    return most_common_class(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "os.chdir('/sharedfolder/sida_classifier/test_clips/')\n",
    "!rm *_3_sec_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/sharedfolder/sida_classifier/test_clips/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3bec3dad9105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/sharedfolder/sida_classifier/test_clips/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#os.chdir('/sharedfolder/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/sharedfolder/sida_classifier/test_clips/'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "## Classifying a long audio file\n",
    "\n",
    "resolution_secs = 1\n",
    "classifier_threshold = 0.30\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/test_clips/')\n",
    "#os.chdir('/sharedfolder/')\n",
    "\n",
    "errors = []\n",
    "\n",
    "import datetime\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "#media_path = \"/sharedfolder/sida_classifier_mbmbam_v2/test_clips/\" + wav_filename\n",
    "\n",
    "media_path = \"/sharedfolder/sida_classifier/test_clips/LM_03_John-Prine_1976-06-13_CAS_A_SRM.wav\"\n",
    "\n",
    "#os.chdir('/sharedfolder/The_World_batch/The_World_WGBH_episodes/')\n",
    "\n",
    "#media_path = random.choice([item for item in os.listdir('./') if '.wav' in item])\n",
    "\n",
    "time_str = str(datetime.datetime.now()).replace(':', '').split('.')[0].replace(' ', '_')\n",
    "\n",
    "csv_path = media_path[:-4]+'_applause_mlpc4096_labels_100-500Hz_scaled_'+str(resolution_secs)+'s_' + time_str +'.csv'\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications = []\n",
    "with open(csv_path,'w') as fo:\n",
    "    fo.write('')\n",
    "\n",
    "for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "    try:\n",
    "        snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "        mode_id, mode_id_percentage = classify_clip('/tmp/temp_clip.wav')\n",
    "        os.remove('/tmp/temp_clip.wav')\n",
    "        \n",
    "        top_label = speaker_list[mode_id]\n",
    "        if mode_id_percentage > classifier_threshold:\n",
    "            with open(csv_path,'a') as fo:\n",
    "                duration = resolution_secs\n",
    "                start = i * resolution_secs\n",
    "                fo.write(str(start) + ',' + str(duration) +','+ str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')\n",
    "    except Exception as e:\n",
    "        errors.append(e)\n",
    "        print(\"Error: \" + str(i))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## BATCH classifying long audio files\n",
    "\n",
    "resolution_secs = 1\n",
    "classifier_threshold = 0.30\n",
    "\n",
    "\n",
    "errors = []\n",
    "\n",
    "import datetime\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "#media_path = \"/sharedfolder/sida_classifier_mbmbam_v2/test_clips/\" + wav_filename\n",
    "\n",
    "media_dir = \"/sharedfolder/sida_classifier/LM_Live_Recordings/\"\n",
    "\n",
    "os.chdir(media_dir)\n",
    "media_paths = [item for item in os.listdir('./') if (item[-4:].lower() in ('.mp3','.wav','.mp4')) & (item[0]!='.')]\n",
    "random.shuffle(media_paths)\n",
    "\n",
    "for media_path in media_paths:\n",
    "\n",
    "    time_str = str(datetime.datetime.now()).replace(':', '').split('.')[0].replace(' ', '_')\n",
    "\n",
    "    csv_path = media_path[:-4]+'_applause_mlpc4096_labels_100-16kHz_scaled_'+str(resolution_secs)+'s_' + time_str +'.csv'\n",
    "\n",
    "    snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "    classifications = []\n",
    "    with open(csv_path,'w') as fo:\n",
    "        fo.write('')\n",
    "\n",
    "    for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "        try:\n",
    "            snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "            mode_id, mode_id_percentage = classify_clip('/tmp/temp_clip.wav')\n",
    "            os.remove('/tmp/temp_clip.wav')\n",
    "\n",
    "            top_label = speaker_list[mode_id]\n",
    "            if mode_id_percentage > classifier_threshold:\n",
    "                if mode_id==0:\n",
    "                    with open(csv_path,'a') as fo:\n",
    "                        duration = resolution_secs\n",
    "                        start = i * resolution_secs\n",
    "                        fo.write(str(start) + ',' + str(duration) +','+ str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')\n",
    "        except Exception as e:\n",
    "            errors.append(e)\n",
    "            print(\"Error: \" + str(i))\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time elapsed: \"+str(timeit.default_timer() - tic))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(errors))\n",
    "print(list(set([item[0] for item in errors])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
