{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U git+git://github.com/hipstas/audio-tagging-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/training_set/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved features\n",
    "\n",
    "def load_features(dir_path):\n",
    "    features = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        with open(os.path.join(dir_path, filename)) as fi:\n",
    "            csv_reader = csv.reader(fi)\n",
    "            for row in csv_reader:\n",
    "                features.append([float(item) for item in row])\n",
    "    return features\n",
    "\n",
    "gross_features = load_features('/sharedfolder/sida_classifier/training_set/_classes_NPR_Fresh_Air_20_episodes/Terry_Gross/_vowel_mfccs_and_deltas')\n",
    "print(len(gross_features))\n",
    "\n",
    "fresh_air_ubm_features = load_features('/sharedfolder/sida_classifier/training_set/_classes_NPR_Fresh_Air_20_episodes/Terry_Gross/_vowel_mfccs_and_deltas')\n",
    "print(len(fresh_air_ubm_features))\n",
    "\n",
    "m_ubm_features = load_features('/sharedfolder/sida_classifier/AAPB_male_vowel_mfccs_and_deltas')\n",
    "print(len(m_ubm_features))\n",
    "\n",
    "f_ubm_features = load_features('/sharedfolder/sida_classifier/AAPB_female_vowel_mfccs_and_deltas')\n",
    "print(len(f_ubm_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing MFCCs and deltas for a single frame\n",
    "\n",
    "print(random.choice(gross_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining feature sets\n",
    "\n",
    "speaker_1_mfccs = gross_features\n",
    "ubm_mfccs = fresh_air_ubm_features + m_ubm_features + f_ubm_features\n",
    "\n",
    "print(len(speaker_1_mfccs))\n",
    "print(len(ubm_mfccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and evaluating a simple multi-layer perceptron model\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "X = speaker_1_mfccs[:-len(speaker_1_mfccs)/10] + ubm_mfccs[:-len(ubm_mfccs)/10]\n",
    "y = [1]*len(speaker_1_mfccs[:-len(speaker_1_mfccs)/10]) + [0]*len(ubm_mfccs[:-len(ubm_mfccs)/10])\n",
    "\n",
    "X_test = speaker_1_mfccs[-len(speaker_1_mfccs)/10:] + ubm_mfccs[-len(ubm_mfccs)/10:]\n",
    "y_test = [1]*len(speaker_1_mfccs[-len(speaker_1_mfccs)/10:]) + [0]*len(ubm_mfccs[-len(ubm_mfccs)/10:])\n",
    "\n",
    "#classifier = ExtraTreesClassifier().fit(X, y)\n",
    "classifier = MLPClassifier().fit(X, y)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and saving an MLP model with all training data\n",
    "\n",
    "X = speaker_1_mfccs + ubm_mfccs\n",
    "y = [1]*len(speaker_1_mfccs) + [0]*len(ubm_mfccs)\n",
    "\n",
    "#classifier = ExtraTreesClassifier().fit(X, y)\n",
    "classifier = MLPClassifier().fit(X, y)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(classifier, 'Terry_Gross_vowels_et_2048.pkl')\n",
    "classifier = joblib.load('Terry_Gross_vowels_et_2048.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#### Start here to load pre-trained model ####\n",
    "##############################################\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "#classifier = joblib.load('Terry_Gross_vowels_mlpc_2048.pkl')\n",
    "#classifier = joblib.load('Terry_Gross_vowels_mlpc_2048.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Download and unzip a set of 358 3-second Fresh Air clips\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "!wget -N https://github.com/hipstas/shaping-humanities-data/blob/master/audio/Fresh_Air_2017-07-31_3-sec_clips.zip?raw=true -O Fresh_Air_2017-07-31_3-sec_clips.zip\n",
    "!unzip Fresh_Air_2017-07-31_3-sec_clips.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "#### Repeat this cell several times to help choose a classifier threshold value.\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/Fresh_Air_2017-07-31_3-sec_clips/')\n",
    "\n",
    "wav_pathname = os.path.abspath(random.choice(os.listdir('./')))\n",
    "\n",
    "test_mfccs = attk.get_mfccs_and_deltas(wav_pathname)\n",
    "\n",
    "print(wav_pathname)\n",
    "\n",
    "results = classifier.predict(test_mfccs)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = attk.get_vowel_segments(wav_pathname)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if vowel_bools[i]==True:\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(wav_pathname))\n",
    "\n",
    "print(\"All samples: \"+str(np.mean(results)))\n",
    "print(\"Vowels only: \"+str(np.mean(vowel_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function that classifies vowel segments only and returns \n",
    "## average output for the full clip\n",
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs = attk.get_mfccs_and_deltas(clip_pathname)\n",
    "    results = classifier.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = attk.get_vowel_segments(clip_pathname)\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classify_clip(wav_pathname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Classifying a long audio file\n",
    "\n",
    "resolution_secs = 5.0\n",
    "\n",
    "os.chdir('/sharedfolder/')\n",
    "\n",
    "!wget -N https://github.com/hipstas/shaping-humanities-data/blob/master/audio/Fresh_Air_2017-07-31.mp3?raw=true -O Fresh_Air_2017-07-31.mp3\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "media_path = \"/sharedfolder/Fresh_Air_2017-07-31.mp3\"\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications = []\n",
    "\n",
    "for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "    try:\n",
    "        snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "        classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "    except:\n",
    "        classifications.append(0.0)\n",
    "        print(\"Error: \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Time elapsed: \"+str(timeit.default_timer() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Writing classification output to CSV\n",
    "\n",
    "classifier_threshold = 0.06\n",
    "\n",
    "classifier_output = []\n",
    "\n",
    "for classification in attk.smooth(np.array(classifications)):\n",
    "    if classification < classifier_threshold:\n",
    "        classifier_output.append(0)\n",
    "    if classification >= classifier_threshold:\n",
    "        classifier_output.append(1)\n",
    "\n",
    "csv_path = media_path[:-4]+'_mlpc2048_labels.csv'\n",
    "csv_path = media_path[:-4]+'_extratrees2048_labels.csv'\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    for pair in attk.labels_to_ranges(classifier_output, label=1):\n",
    "        start = pair[0] * resolution_secs\n",
    "        duration = (pair[1] - pair[0]) * resolution_secs\n",
    "        fo.write(str(start) + ',' + str(start + duration) + ',Terry Gross\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
