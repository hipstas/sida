{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import shutil\n",
    "import subprocess\n",
    "import os\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import pyAudioAnalysis\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from pyAudioAnalysis import audioBasicIO as aIO\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "os.chdir(os.path.expanduser('~/Dropbox/smacpy'))\n",
    "from smacpy import Smacpy\n",
    "\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpb-aacip-75-88qbzvhx.h264.mp4\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "#### WAV path for testing purposes ####\n",
    "\n",
    "speaker_value=\"Nixon, Richard\"\n",
    "audio_path=\"/Users/mclaugh/Desktop/AAPB_400_hrs_labeled/wav/cpb-aacip-75-88qbzvhx.h264.wav\"\n",
    "filename=audio_path.split('/')[-1][:-4]+'.mp4' ## kludge\n",
    "print(filename)\n",
    "\n",
    "#######################################\n",
    "\n",
    "label_table_path=\"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-data/AAPB_corpus_metadata/AAPB_speech_labels_full_corpus_170425.csv\"\n",
    "label_table = pd.read_csv(label_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16.0, 23.0),\n",
       " (1923.0, 1928.0),\n",
       " (1981.0, 2015.0),\n",
       " (2056.0, 2087.0),\n",
       " (2197.0, 2213.0),\n",
       " (2962.0, 2976.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating dictionary of label values for a given speaker.\n",
    "\n",
    "\n",
    "speaker_range_dict={}\n",
    "\n",
    "# extracting rows associated with specified speaker\n",
    "speaker_rows = label_table[label_table['Value']==speaker_value]\n",
    "\n",
    "# creating a list of all relevant filenames\n",
    "speaker_filenames = sorted([item for item in list(set(list(speaker_rows['Filename']))) if str(item)!='nan'])\n",
    "\n",
    "for filename in speaker_filenames:\n",
    "    filename_rows = label_table[label_table['Filename']==filename]\n",
    "    speaker_ranges=[]\n",
    "    for index, row in filename_rows.iterrows():\n",
    "        row = label_table.iloc[index]\n",
    "        speaker_ranges.append((float(row['Timecode IN']),float(row['Timecode OUT'])))\n",
    "    speaker_range_dict[filename]=speaker_ranges\n",
    "\n",
    "#test\n",
    "speaker_range_dict[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Downsampling and applying bandpass filter ###\n",
    "\n",
    "wav_path = '/var/tmp/'+filename+'.wav'\n",
    "\n",
    "subprocess.call(['ffmpeg', '-y', '-i', audio_path, '-ar', '16000', '-ac', '1', '-af', \"volume=0.99,highpass=f=150,lowpass=f=5500\",wav_path])\n",
    "\n",
    "\n",
    "## Full-quality version for the sake of feature extraction\n",
    "\n",
    "wav_path_hifi = '/var/tmp/'+filename+'.hifi.wav'\n",
    "\n",
    "subprocess.call(['ffmpeg', '-y', '-i', audio_path, wav_path_hifi])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Extracting formants with Praat ###\n",
    "\n",
    "def extract_formants(wav_path):\n",
    "    formant_lol = [line.split(',') for line in subprocess.check_output([\"/Applications/Praat.app/Contents/MacOS/Praat\", \\\n",
    "                \"--run\", \"/Volumes/McLaughlin-6TB-1/Dropbox/smacpy/extract_formants.praat\", \\\n",
    "                wav_path_hifi]).splitlines()]\n",
    "\n",
    "    formant_table = pd.DataFrame(formant_lol[1:],columns=formant_lol[0])\n",
    "    formant_table = formant_table.replace({'--undefined--':np.nan}) ## handling Praat's notation for undefined values\n",
    "\n",
    "    formant_table['F1']=formant_table['F1'].astype(float,error='coerce')  ## Converting all values to float\n",
    "    formant_table['F2']=formant_table['F2'].astype(float,error='coerce')\n",
    "    formant_table['F3']=formant_table['F3'].astype(float,error='coerce')\n",
    "    formant_table['F4']=formant_table['F4'].astype(float,error='coerce')\n",
    "    formant_table['starttime']=formant_table['starttime'].astype(float,error='coerce')\n",
    "    formant_table['endtime']=formant_table['endtime'].astype(float,error='coerce')\n",
    "\n",
    "    for index, row in formant_table.iterrows():       ## Rounding start and end time values returned by Praat\n",
    "        row=formant_table.iloc[index]\n",
    "        row['starttime']=round(row['starttime'],3)\n",
    "        row['endtime']=round(row['starttime'],3)\n",
    "\n",
    "    return formant_table\n",
    "\n",
    "\n",
    "\n",
    "#formant_table = extract_formants(wav_path_hifi)\n",
    "#formant_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating parameters and recalculating filters: \n",
      "('Nyquist: ', 8000.0)\n",
      "minHz:0\n",
      "maxHz:8000.0\n",
      "minMel:0.0\n",
      "maxMel:2840.06412216\n",
      "\n",
      "Reading /var/tmp/cpb-aacip-75-88qbzvhx.h264.mp4.wav\n",
      "    Training a GaussianMixture for label a, using data of shape (55375, 13)\n",
      "  Trained 1 classes from 1 input files\n",
      "Reading /var/tmp/cpb-aacip-75-88qbzvhx.h264.mp4.wav\n"
     ]
    }
   ],
   "source": [
    "def extract_mfccs(wav_path):\n",
    "    model = Smacpy(\"\", {wav_path:'a'})\n",
    "    return pd.DataFrame(model.file_to_features(wav_path))\n",
    "\n",
    "\n",
    "#mfccs = extract_mfccs(wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### list of seconds values like [1,2,9,10]\n",
    "### to inclusive ranges like [(1,3),(9,11)]\n",
    "\n",
    "def seconds_list_to_ranges(seconds_list): \n",
    "    ranges = []                \n",
    "    for k, g in groupby(enumerate(seconds_list), lambda (i,x):i-x):\n",
    "        group = map(itemgetter(1), g)\n",
    "        ranges.append((group[0], group[-1]+1)) ## Adding 1 to make each range inclusive\n",
    "    return ranges\n",
    "\n",
    "\n",
    "### Hann smoothing\n",
    "\n",
    "def smooth(x_in,window_len=10,window='hanning'):\n",
    "        x=np.array(x_in)\n",
    "        if x.ndim != 1:\n",
    "                raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "        if x.size < window_len:\n",
    "                raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "        if window_len<3:\n",
    "                return x\n",
    "        if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "        s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:  \n",
    "                w=eval('np.'+window+'(window_len)')\n",
    "        y=np.convolve(w/w.sum(),s,mode='same')\n",
    "        return list(y[window_len:-window_len+1])\n",
    "\n",
    "\n",
    "### Range intersection function cribbed from BallpointBen's comment here:\n",
    "### https://stackoverflow.com/questions/40367461/intersection-of-two-lists-of-ranges-in-python\n",
    "\n",
    "\n",
    "def intersects(a,b):\n",
    "    ranges = []\n",
    "    i = j = 0\n",
    "    while i < len(a) and j < len(b):\n",
    "        a_left, a_right = a[i]\n",
    "        b_left, b_right = b[j]\n",
    "        end_pts = sorted([a_left, a_right, b_left, b_right])\n",
    "        middle = [end_pts[1], end_pts[2]]\n",
    "\n",
    "        if a_right < b_right:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "        if a_right >= b_left and b_right >= a_left:\n",
    "            ranges.append(middle)\n",
    "\n",
    "    for i in range(len(ranges)-1):\n",
    "        if ranges[i][1] in (ranges[i+1][0], ranges[i+1][0]-1):\n",
    "            ranges[i:i+2] = [[ranges[i][0], ranges[i+1][1]]]\n",
    "\n",
    "    return ranges\n",
    "\n",
    "#a = [[0,2.5], [5,9.9], [10,24.9]]\n",
    "#b = [[1,5], [8,12], [15,18],[20,20.001], [21,24]]\n",
    "#print(intersects(a,b))\n",
    "# [[1, 2], [5, 5], [8, 10], [15, 18], [20, 24]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.Series([float(item) for item in list(formant_table['F1'])]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Male-female classification\n",
    "\n",
    "### 0 is male, 1 is female\n",
    "### calculated at 1-second resolution\n",
    "\n",
    "\n",
    "def find_male_ranges(wav_path):\n",
    "    [mf_classes, classesAll, acc, CM] = aS.mtFileClassification(wav_path, \"data/svmSpeakerFemaleMale\", \"svm\", False)\n",
    "    #classes = list(mf_classes) ## non-smoothed output\n",
    "    smoothed_classes = [round(item) for item in smooth([int(item) for item in list(mf_classes)],window_len=7)] \n",
    "    counter=0\n",
    "    male_secs=[]\n",
    "    for segment in smoothed_classes:\n",
    "        if segment < 1.0:\n",
    "            male_secs.append(counter)\n",
    "        counter+=1\n",
    "    return seconds_list_to_ranges(male_secs)\n",
    "\n",
    "\n",
    "## Female-male classification\n",
    "\n",
    "### 0 is female, 1 is female\n",
    "### calculated at 1-second resolution\n",
    "\n",
    "\n",
    "def find_female_ranges(wav_path):\n",
    "    [mf_classes, classesAll, acc, CM] = aS.mtFileClassification(wav_path, \"data/svmSpeakerFemaleMale\", \"svm\", False)\n",
    "    #classes = list(mf_classes) ## non-smoothed output\n",
    "    smoothed_classes = [round(item) for item in smooth([int(item) for item in list(mf_classes)],window_len=7)] \n",
    "    counter=0\n",
    "    female_secs=[]\n",
    "    for segment in smoothed_classes:\n",
    "        if segment > 0.0:\n",
    "            female_secs.append(counter)\n",
    "        counter+=1\n",
    "    return seconds_list_to_ranges(female_secs)\n",
    "\n",
    "\n",
    "#male_ranges = find_male_ranges(wav_path)\n",
    "#print(male_ranges)\n",
    "\n",
    "#female_ranges = find_female_ranges(wav_path)\n",
    "#print(female_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## speech classification\n",
    "\n",
    "### 0 is speech, 1 is music\n",
    "### ['speech', 'music']\n",
    "\n",
    "def find_non_music_ranges(wav_path):\n",
    "    [classes, classesAll, acc, CM] = aS.mtFileClassification(wav_path, \"data/svmSM\", \"svm\", False)\n",
    "    counter=0\n",
    "    non_music_secs=[]\n",
    "    for segment in classes:\n",
    "        if segment < 1.0:\n",
    "            non_music_secs.append(counter)\n",
    "        counter+=1\n",
    "    return seconds_list_to_ranges(non_music_secs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_music_ranges = find_non_music_ranges(wav_path_hifi)\n",
    "\n",
    "print(non_music_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## applause classification\n",
    "\n",
    "### 0 is non-applause, 1 is applause\n",
    "\n",
    "def find_non_applause_ranges(wav_path):\n",
    "    [classes, classesAll, acc, CM] = aS.mtFileClassification(wav_path, \"data/svm_applause_model\", \"svm\", False)\n",
    "    counter=0\n",
    "    non_applause_secs=[]\n",
    "    for segment in classes:\n",
    "        if segment < 1.0:\n",
    "            non_applause_secs.append(counter)\n",
    "        counter+=1\n",
    "    return seconds_list_to_ranges(non_applause_secs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_applause_ranges = find_non_applause_ranges(wav_path_hifi)\n",
    "\n",
    "print(non_applause_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_non_silence_ranges(wav_path):\n",
    "    [Fs, x] = aIO.readAudioFile(wav_path)\n",
    "    segments = aS.silenceRemoval(x, Fs, 0.020, 0.020, smoothWindow = 1.0, Weight = 0.3, plot = False)\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_silence_ranges = find_non_silence_ranges(wav_path_hifi)\n",
    "\n",
    "non_silence_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech_ranges = intersects(non_applause_ranges, intersects(non_music_ranges,non_silence_ranges)) ## intersecting 3 range lists\n",
    "\n",
    "speech_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speaker_range_dict[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersects(speech_ranges,speaker_range_dict[filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "## Enter Speaker Name Here ##\n",
    "#############################\n",
    "\n",
    "speaker = \"Clinton, Hillary\"\n",
    "\n",
    "corpus_dir = \"/Volumes/McLaughlin-6TB-1/Dropbox/aapb-hipstas/Model_training_clips/\"\n",
    "\n",
    "#############################\n",
    "\n",
    "last_name = speaker.split(', ')[0]\n",
    "\n",
    "print(speaker)\n",
    "print(last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ubm_dir = os.path.join(corpus_dir,'UBM_'+last_name)\n",
    "\n",
    "\n",
    "speaker_dir =os.path.join(corpus_dir,speaker)\n",
    "\n",
    "num_speaker_clips=len([item for item in os.listdir(speaker_dir) if item.lower()[-4:]=='.wav'])\n",
    "\n",
    "smacpy_dict={}\n",
    "\n",
    "for filename in [item for item in os.listdir(ubm_dir) if '.wav' in item]:\n",
    "    smacpy_dict[os.path.join(ubm_dir,filename)]=\"background\"\n",
    "\n",
    "for filename in [item for item in os.listdir(speaker_dir) if '.wav' in item]:\n",
    "    smacpy_dict[os.path.join(speaker_dir,filename)]=speaker_dir.strip('/').split('/')[-1]\n",
    "\n",
    "model = Smacpy(\"\", smacpy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_audio_file(audio_pathname):\n",
    "    segments_dir_temp = os.path.join(corpus_dir, last_name+'_segments_1_sec')\n",
    "    basename = audio_pathname.split('/')[-1][:-4]\n",
    "    try:\n",
    "        os.mkdir(segments_dir_temp)\n",
    "        subprocess.call(['ffmpeg','-i',audio_pathname,'-n','-f','segment','-segment_time','1','-c','copy',os.path.join(segments_dir_temp,basename+\"_sec_%05d.wav\")])\n",
    "    except:\n",
    "        print(\"Apparently already processed: \"+audio_pathname)\n",
    "    seg_pathnames = [os.path.join(segments_dir_temp, item) for item in os.listdir(segments_dir_temp) if item.lower()[-4:]=='.wav']\n",
    "    output=[]\n",
    "    global speaker\n",
    "    for filename in [item for item in seg_pathnames if '.wav' in item]:\n",
    "        if model.classify(filename) == speaker:\n",
    "            output.append(1)\n",
    "        else:\n",
    "            output.append(0)\n",
    "    \n",
    "    counter=0\n",
    "    speaker_secs=[]\n",
    "    for segment in output:\n",
    "        if segment>0.0:\n",
    "            speaker_secs.append(counter)\n",
    "        counter+=1\n",
    "    speaker_ranges = seconds_list_to_ranges(speaker_secs)\n",
    "    csv_pathname = audio_pathname[:-4]+'_GMM_UBM_'+last_name+'_'+str(num_speaker_clips)+\"x2s.csv\"\n",
    "    with open(csv_pathname, 'w') as csv_fo:\n",
    "        speaker_ranges_expanded=[(start,1,end-start+1) for start,end in speaker_ranges]\n",
    "        csv_writer = csv.writer(csv_fo)\n",
    "        csv_writer.writerows(speaker_ranges_expanded)\n",
    "    ## Smooth version\n",
    "    output_smooth_temp = list(smooth(np.array(output),window_len=10))\n",
    "    output_smooth=[]\n",
    "    for item in output_smooth_temp:\n",
    "        output_smooth.append(round(item))\n",
    "    counter=0\n",
    "    speaker_secs=[]\n",
    "    for segment in output_smooth:\n",
    "        if segment>0.0:\n",
    "            speaker_secs.append(counter)\n",
    "        counter+=1\n",
    "    speaker_ranges = seconds_list_to_ranges(speaker_secs)\n",
    "    csv_smooth_pathname = audio_pathname[:-4]+'_GMM_UBM_smooth10_'+last_name+'_'+str(num_speaker_clips)+\"x2s.csv\"\n",
    "    with open(csv_smooth_pathname, 'w') as csv_fo:\n",
    "        speaker_ranges_expanded=[(start,1,end-start+1) for start,end in speaker_ranges]\n",
    "        csv_writer = csv.writer(csv_fo)\n",
    "        csv_writer.writerows(speaker_ranges_expanded)\n",
    "    shutil.rmtree(segments_dir_temp)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_set_dir=\"/Volumes/U/AAPB_Corpus_May_2017/Test_Sets/AAPB_Test_Haystack_\"+last_name\n",
    "\n",
    "to_classify=[os.path.join(test_set_dir,item) for item in os.listdir(test_set_dir) if ('.wav' in item)&(item[0]!='.')]\n",
    "\n",
    "for pathname in to_classify:\n",
    "    classify_audio_file(pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
