{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applause/Speech Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "import pandas as pd\n",
    "\n",
    "!mkdir -p /sharedfolder/applause_classifier/\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/')\n",
    "\n",
    "# A directory that would contain subdirectories of full-length audio \n",
    "# recordings in the speaker recognition version of this notebook. \n",
    "# In this case we're using pre-segmented audio collections, so the \n",
    "# 'Applause' directory only contains one directory: `_classes_Audio`.\n",
    "training_audio_dir_name = \"Applause\"\n",
    "\n",
    "# A directory containing pre-segmented audio training sets in two or \n",
    "# more subdirectories.\n",
    "class_dir_pathname = '/sharedfolder/applause_classifier/_classes_' + training_audio_dir_name\n",
    "\n",
    "# Creating the directories we need, in case they don't already exist.\n",
    "subprocess.call(['mkdir', '-p', class_dir_pathname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading male and female training data: our 'background' set, \n",
    "# which we will use to create a universal background model (UBM) for \n",
    "# our classifier, putatively representing all speakers in the world.\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/')\n",
    "\n",
    "!wget -N http://xtra.arloproject.com/datasets/audio/Mozilla_CV_UBM_Subset/females_5k.zip\n",
    "!wget -N http://xtra.arloproject.com/datasets/audio/Mozilla_CV_UBM_Subset/males_5k.zip\n",
    "!wget -N http://xtra.arloproject.com/datasets/aapb-ubm/Male_AAPB_171110.zip\n",
    "!wget -N http://xtra.arloproject.com/datasets/aapb-ubm/Female_AAPB_171110.zip\n",
    "\n",
    "!unzip -o females_5k.zip\n",
    "!unzip -o males_5k.zip\n",
    "!unzip -o Male_AAPB_171110.zip\n",
    "!unzip -o Female_AAPB_171110.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading applause training data from GitHub.\n",
    "# Roughly half the WAVs in this collection come from the PennSound \n",
    "# poetry archive, the rest from speeches and public appearances by \n",
    "# Bill Clinton.\n",
    "\n",
    "!git clone https://github.com/hipstas/applause-classifier.git\n",
    "    \n",
    "# The `!` character at the start of the line above is known as a \n",
    "# 'magic' in Jupyter. The following command runs in bash -- \n",
    "# not great style if you're developing a Python script or package, \n",
    "# but quick and readable for everyday work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating directories for our two classes:\n",
    "#     /sharedfolder/applause_classifier/_classes_Audio/Applause/ \n",
    "#     /sharedfolder/applause_classifier/_classes_Audio/Non-Applause/\n",
    "\n",
    "applause_path = os.path.join(class_dir_pathname, 'Applause')\n",
    "non_applause_path = os.path.join(class_dir_pathname, 'Non-Applause')\n",
    "\n",
    "subprocess.call(['mkdir', applause_path])\n",
    "subprocess.call(['mkdir', non_applause_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Consolidating all non-applause clips in a single directory \n",
    "# using bash, via Jupyter's `!` magic character.\n",
    "\n",
    "!mv females_5k/* '/sharedfolder/applause_classifier/_classes_Applause/Non-Applause'\n",
    "!mv males_5k/* '/sharedfolder/applause_classifier/_classes_Applause/Non-Applause'\n",
    "!mv Male_AAPB_171110/* '/sharedfolder/applause_classifier/_classes_Applause/Non-Applause'\n",
    "!mv Female_AAPB_171110/* '/sharedfolder/applause_classifier/_classes_Applause/Non-Applause'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unzipping applause training data.\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/applause-classifier')\n",
    "\n",
    "!unzip -o Applause_from_Bill_Clinton_speeches_1.zip\n",
    "!unzip -o Applause_from_Bill_Clinton_speeches_2.zip\n",
    "!unzip -o applause_pt1.zip\n",
    "!unzip -o applause_pt2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moving all applause WAV clips (located in the 4 directories we \n",
    "# created in the previous cell) to the master Applause class directory.\n",
    "\n",
    "!mv */*.wav '/sharedfolder/applause_classifier/_classes_Applause/Applause'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Extracting features (MFCCs, deltas, and delta-deltas) from all clips, then writing features to CSVs\n",
    "# (Note that we are not extracting vowel segments like we do with speech classifiers.)\n",
    "\n",
    "# Notes: \n",
    "# The `%%capture` magic above suppresses a cell's output.\n",
    "\n",
    "# If you aren't getting the results you expect when you run this cell, \n",
    "# comment out the `%%capture` line to check for error messages.\n",
    "# (The `moviepy` package is extremely verbose; while running large-scale \n",
    "# jobs, your browser may run out of memory.)\n",
    "above \n",
    "os.chdir(class_dir_pathname)\n",
    "\n",
    "for dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "    print(\"> Starting \" + dir_name)\n",
    "    try:\n",
    "        os.chdir(os.path.join(class_dir_pathname, dir_name))\n",
    "        try: os.mkdir('./_mfccs_and_deltas')\n",
    "        except: pass\n",
    "        filenames = [item for item in os.listdir('./') if item[-4:].lower()=='.wav']\n",
    "        for filename in filenames:\n",
    "            csv_out_path = './_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv'\n",
    "            if not os.path.isfile(csv_out_path):\n",
    "                try:\n",
    "                    mfccs = attk.get_mfccs_and_deltas(filename, n_mfcc=30, n_fft=4096, freq_min=100, freq_max=16000)\n",
    "                    if len(mfccs) > 0:\n",
    "                        with open(csv_out_path, 'w') as fo:\n",
    "                            csv_writer = csv.writer(fo)\n",
    "                            csv_writer.writerows(mfccs)  \n",
    "                except Exception as e:\n",
    "                    print('FILE ERROR: ' + filename)\n",
    "                    print(e)\n",
    "    except Exception as e:\n",
    "        print('SKIPPING DIRECTORY: ' + dir_name)     ## Skipping class directories for which we didn't extract vowels\n",
    "        #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue to the next notebook to train and run the applause classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
