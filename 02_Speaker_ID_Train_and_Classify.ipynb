{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/training_set/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load saved features\n",
    "\n",
    "def load_features(dir_path):\n",
    "    features = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        with open(os.path.join(dir_path, filename)) as fi:\n",
    "            csv_reader = csv.reader(fi)\n",
    "            for row in csv_reader:\n",
    "                features.append([float(item) for item in row])\n",
    "    return features\n",
    "\n",
    "speaker_1_features = load_features('/sharedfolder/sida_classifier/training_set/_classes_The_World_WGBH_100_episodes/Marco_Werman/_vowel_mfccs_and_deltas')\n",
    "print(len(speaker_1_features))\n",
    "\n",
    "program_ubm_male_features = load_features('/sharedfolder/sida_classifier/training_set/_classes_The_World_WGBH_100_episodes/Male/_vowel_mfccs_and_deltas')\n",
    "print(len(program_ubm_male_features))\n",
    "\n",
    "program_ubm_female_features = load_features('/sharedfolder/sida_classifier/training_set/_classes_The_World_WGBH_100_episodes/Female/_vowel_mfccs_and_deltas')\n",
    "print(len(program_ubm_female_features))\n",
    "\n",
    "aapb_ubm_male_features = load_features('/sharedfolder/sida_classifier/AAPB_male_vowel_mfccs_and_deltas')\n",
    "print(len(aapb_ubm_male_features))\n",
    "\n",
    "aapb_ubm_female_features = load_features('/sharedfolder/sida_classifier/AAPB_female_vowel_mfccs_and_deltas')\n",
    "print(len(aapb_ubm_female_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Printing MFCCs and deltas for a single frame\n",
    "\n",
    "print(random.choice(speaker_1_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Combining feature sets\n",
    "\n",
    "speaker_1_features = speaker_1_features\n",
    "ubm_features = program_ubm_male_features + program_ubm_female_features + aapb_ubm_male_features + aapb_ubm_female_features\n",
    "\n",
    "print(len(speaker_1_features))\n",
    "print(len(ubm_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training and evaluating a simple multi-layer perceptron model\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = speaker_1_features[:-len(speaker_1_features)/10] + ubm_features[:-len(ubm_features)/10]\n",
    "y = [1]*len(speaker_1_features[:-len(speaker_1_features)/10]) + [0]*len(ubm_features[:-len(ubm_features)/10])\n",
    "\n",
    "X_test = speaker_1_features[-len(speaker_1_features)/10:] + ubm_features[-len(ubm_features)/10:]\n",
    "y_test = [1]*len(speaker_1_features[-len(speaker_1_features)/10:]) + [0]*len(ubm_features[-len(ubm_features)/10:])\n",
    "\n",
    "classifier = MLPClassifier().fit(X, y)\n",
    "\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training and saving an MLP model with all training data\n",
    "\n",
    "X = speaker_1_features + ubm_features\n",
    "y = [1]*len(speaker_1_features) + [0]*len(ubm_features)\n",
    "\n",
    "classifier = MLPClassifier().fit(X, y)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(classifier, 'Marco_Werman_vowels_mlpc_2048.pkl')\n",
    "classifier = joblib.load('Marco_Werman_vowels_mlpc_2048.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################\n",
    "#### Start here to load pre-trained model ####\n",
    "##############################################\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "classifier = joblib.load('Marco_Werman_vowels_mlpc_2048.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Download unseen audio and split into 3-second WAV clips for testing\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/')\n",
    "\n",
    "try: os.mkdir('3_sec_clips/')\n",
    "except: pass\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/3_sec_clips/')\n",
    "\n",
    "!wget -N https://www.podtrac.com/pts/redirect.mp3/cdn.pri.org/sites/default/files/pris-world/episode-audio/20170814full.mp3\n",
    "!ffmpeg -i \"20170814full.mp3\" \"20170814full.wav\" \n",
    "!ffmpeg -i \"20170814full.wav\" -f segment -segment_time 3 \"20170814full_3_sec_%04d.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "#### Repeat this cell several times to help choose a classifier threshold value.\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier/3_sec_clips/')\n",
    "\n",
    "wav_pathname = os.path.abspath(random.choice([item for item in os.listdir('./') if '3_sec' in item]))\n",
    "\n",
    "test_features = attk.get_mfccs_and_deltas(wav_pathname)\n",
    "\n",
    "print(wav_pathname)\n",
    "\n",
    "results = classifier.predict(test_features)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = attk.get_vowel_segments(wav_pathname)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if vowel_bools[i]==True:\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(wav_pathname))\n",
    "\n",
    "print(\"All samples: \"+str(np.mean(results)))\n",
    "print(\"Vowels only: \"+str(np.mean(vowel_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function that classifies vowel segments only and returns \n",
    "## average output for the full clip\n",
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs = attk.get_mfccs_and_deltas(clip_pathname)\n",
    "    results = classifier.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = attk.get_vowel_segments(clip_pathname)\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Classifying a long audio file\n",
    "\n",
    "resolution_secs = 3.0\n",
    "\n",
    "os.chdir('/sharedfolder/')\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "media_path = \"/sharedfolder/sida_classifier/3_sec_clips/20170814full.mp3\"\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications = []\n",
    "\n",
    "for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "    try:\n",
    "        snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "        classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "    except:\n",
    "        classifications.append(0.0)\n",
    "        print(\"Error: \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Time elapsed: \"+str(timeit.default_timer() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Writing classification output to CSV\n",
    "\n",
    "classifier_threshold = 0.2\n",
    "\n",
    "os.chdir('/sharedfolder/sida_classifier')\n",
    "\n",
    "csv_path = media_path[:-4]+'_mlpc2048_labels_'+str(resolution_secs)+'s.csv'\n",
    "\n",
    "counter=0\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    duration = resolution_secs\n",
    "    for value in classifications:\n",
    "        if value >= classifier_threshold:\n",
    "            start = counter * resolution_secs\n",
    "            fo.write(str(start) + ',' + str(duration) +','+ str(value) +',Marco Werman\\n')\n",
    "        counter+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
