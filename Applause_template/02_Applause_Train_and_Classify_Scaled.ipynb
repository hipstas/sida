{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import librosa\n",
    "import timeit\n",
    "import random\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/')\n",
    "\n",
    "speaker_list = ['Applause', 'Non-Applause']\n",
    "\n",
    "speaker_0_label, speaker_1_label = speaker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du /sharedfolder/applause_classifier/_classes_Applause/applause/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved features\n",
    "\n",
    "def load_features(dir_path):\n",
    "    features = []\n",
    "    for filename in os.listdir(dir_path):\n",
    "        try:\n",
    "            with open(os.path.join(dir_path, filename)) as fi:\n",
    "                csv_reader = csv.reader(fi)\n",
    "                for row in csv_reader:\n",
    "                    features.append([float(item) for item in row])\n",
    "        except Exception as e: \n",
    "            print(os.path.join(dir_path, filename))\n",
    "            print(e)\n",
    "    return features\n",
    "\n",
    "speaker_0_features = load_features('/sharedfolder/applause_classifier/_classes_Applause/applause/_mfccs_and_deltas')\n",
    "print(len(speaker_0_features))\n",
    "\n",
    "speaker_1_features = load_features('/sharedfolder/applause_classifier/_classes_Applause/non_applause/_mfccs_and_deltas')\n",
    "print(len(speaker_1_features))\n",
    "\n",
    "\n",
    "min_length = np.min([len(speaker_0_features), len(speaker_1_features)])\n",
    "#speaker_0_features = random.sample(speaker_0_features, min_length)\n",
    "#speaker_1_features = random.sample(speaker_1_features, min_length)\n",
    "\n",
    "\n",
    "#aapb_ubm_male_features = load_features('/sharedfolder/applause_classifier/AAPB_male_vowel_mfccs_and_deltas_100-5K_Hz')\n",
    "#print(len(aapb_ubm_male_features))\n",
    "\n",
    "#aapb_ubm_female_features = load_features('/sharedfolder/applause_classifier/AAPB_female_vowel_mfccs_and_deltas_100-5K_Hz')\n",
    "#print(len(aapb_ubm_female_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing MFCCs and deltas for a single frame\n",
    "\n",
    "print(random.choice(speaker_1_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining feature sets\n",
    "\n",
    "#speaker_1_features = speaker_1_features\n",
    "#male_ubm_features = program_ubm_male_features +  aapb_ubm_male_features \n",
    "#female_ubm_features = program_ubm_female_features + aapb_ubm_female_features\n",
    "\n",
    "#print(len(speaker_1_features))\n",
    "#print(len(male_ubm_features))\n",
    "#print(len(female_ubm_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and multi-layer perceptron model with 9/10 of training data and evaluating performance on remaining 1/10\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/')\n",
    "\n",
    "import random\n",
    "#random.shuffle(speaker_0_features)\n",
    "#random.shuffle(speaker_1_features)\n",
    "#random.shuffle(speaker_2_features)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = speaker_0_features[:-len(speaker_0_features)/10] + speaker_1_features[:-len(speaker_1_features)/10]\n",
    "y = [1]*len(speaker_0_features[:-len(speaker_0_features)/10]) + [0]*len(speaker_1_features[:-len(speaker_1_features)/10])\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y)\n",
    "\n",
    "X_test = speaker_0_features[-len(speaker_0_features)/10:] + speaker_1_features[-len(speaker_1_features)/10:]\n",
    "y_test = [1]*len(speaker_0_features[-len(speaker_0_features)/10:]) + [0]*len(speaker_1_features[-len(speaker_1_features)/10:]) \n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = MLPClassifier(max_iter = 2000, random_state = 9, \\\n",
    "                          hidden_layer_sizes = (100, 100), solver = 'adam', \\\n",
    "                          activation = 'relu').fit(X_train_scaled, y_train)\n",
    "\n",
    "print(classifier.score(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and saving an MLP model with all training data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = speaker_0_features + speaker_1_features\n",
    "y = [0]*len(speaker_0_features) + [1]*len(speaker_1_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "#classifier = MLPClassifier().fit(X_scaled, y)\n",
    "\n",
    "classifier = MLPClassifier(max_iter = 2000, random_state = 9, \\\n",
    "                          hidden_layer_sizes = (100, 100), solver = 'adam', \\\n",
    "                          activation = 'relu').fit(X_scaled, y)\n",
    "\n",
    "trained_model_filename = 'Applause' + '_mlpc_4096_100-16K_scaled_.pkl'\n",
    "print(trained_model_filename)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(classifier, trained_model_filename)\n",
    "joblib.dump(scaler, trained_model_filename.replace('.pkl', '.scaler'))\n",
    "classifier = joblib.load(trained_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.mixture import GaussianMixture\n",
    "\n",
    "#gmm_classifier = GaussianMixture(n_components=3, covariance_type='diag', max_iter=3000).fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#### Start here to load pre-trained model ####\n",
    "##############################################\n",
    "\n",
    "#trained_model_filename = 'mbmbam' + '_vowels_mlpc_4096_100-5K_scaled.pkl'\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier')\n",
    "classifier = joblib.load('Applause_mlpc_4096_100-16K_scaled_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "from pandas.tools.plotting import parallel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=2) #2-dimensional LDA\n",
    "lda_transformed = pd.DataFrame(lda.fit_transform(X_scaled, y))\n",
    "lda_transformed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_transformed['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 mfccs, 4096\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Applause', c='red', alpha=0.2)\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Non_Applause', c='blue', alpha=0.2)\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 mfccs, 2048\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Justin', c='red', alpha=0.1)\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Griffin', c='blue', alpha=0.1)\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==2][0], lda_transformed[lda_transformed['y']==2][1], label='Travis', c='green', alpha=0.1)\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 mfccs, 2048\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Justin', c='red')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Griffin', c='blue')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==2][0], lda_transformed[lda_transformed['y']==2][1], label='Travis', c='green')\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Old\n",
    "\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==0][0], lda_transformed[lda_transformed['y']==0][1], label='Justin', c='red')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==1][0], lda_transformed[lda_transformed['y']==1][1], label='Griffin', c='blue')\n",
    "plt.scatter(lda_transformed[lda_transformed['y']==2][0], lda_transformed[lda_transformed['y']==2][1], label='Travis', c='green')\n",
    "\n",
    "plt.legend(loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "## Download unseen audio and split into 3-second WAV clips for testing\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/')\n",
    "\n",
    "try: os.mkdir('test_clips/')\n",
    "except: pass\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/test_clips/')\n",
    "\n",
    "wav_filename = \"LM_03_John-Prine_1976-06-13_CAS_A_SRM.wav\"\n",
    "\n",
    "\n",
    "#subprocess.call(['wget', '-N', mp3_url])\n",
    "\n",
    "#subprocess.call(['ffmpeg', '-i', mp3_filename, wav_filename])\n",
    "\n",
    "subprocess.call(['ffmpeg', '-i', wav_filename, '-f', 'segment', '-segment_time', '3',  wav_filename[:-4] + '_3_sec_%04d.wav'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_class(class_ids):\n",
    "    mode_id = int(list(scipy.stats.mode(class_ids))[0][0])\n",
    "    mode_id_percentage = float(float(class_ids.count(mode_id))/len(class_ids))\n",
    "    return (mode_id, mode_id_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "#### Repeat this cell several times to help choose a classifier threshold value.\n",
    "\n",
    "import scipy\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/test_clips/')\n",
    "\n",
    "wav_pathname = os.path.abspath(random.choice([item for item in os.listdir('./') if '3_sec' in item]))\n",
    "\n",
    "test_features = np.array(attk.get_mfccs_and_deltas(wav_pathname, n_mfcc=30, n_fft=8192))\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "print(wav_pathname)\n",
    "\n",
    "results = classifier.predict(test_features)  ## Predicting new observation\n",
    "results_proba = classifier.predict_proba(test_features)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "print([round(max(item), 4) for item in list(results_proba)])\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = attk.get_vowel_segments(wav_pathname, n_fft=8192)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if True:                                 #vowel_bools[i]==\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(wav_pathname))\n",
    "\n",
    "print(\"MODE: \" + str(list(scipy.stats.mode(results))[0][0])) \n",
    "print(\"MODE vowels only: \" + str(list(scipy.stats.mode(vowel_results))[0][0])) ## Vowels only\n",
    "#print(\"All samples: \"+str(np.mean(results)))\n",
    "#print(\"Vowels only: \"+str(np.mean(vowel_results)))\n",
    "\n",
    "mode_id, mode_id_percentage = most_common_class(vowel_results)\n",
    "top_label = speaker_list[mode_id]\n",
    "\n",
    "print('')\n",
    "print(\"Speaker: \" + str(top_label))\n",
    "print(\"Confidence: \" + str(mode_id_percentage))\n",
    "\n",
    "print('')\n",
    "\n",
    "print(str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "#### Repeat this cell several times to help choose a classifier threshold value.\n",
    "\n",
    "import scipy\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/test_clips/')\n",
    "\n",
    "#wav_pathname = os.path.abspath(random.choice([item for item in os.listdir('./') if '3_sec' in item]))\n",
    "\n",
    "#test_features = np.array(attk.get_mfccs_and_deltas(wav_pathname))\n",
    "#test_features = scaler.transform(test_features)\n",
    "\n",
    "print(wav_pathname)\n",
    "\n",
    "results = classifier.predict(test_features)  ## Predicting new observation\n",
    "results_proba = classifier.predict_proba(test_features)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "print([round(max(item), 4) for item in list(results_proba)])\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = attk.get_vowel_segments(wav_pathname, n_fft=4096)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if True:  #### vowel_bools[i]==\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(wav_pathname))\n",
    "\n",
    "print(\"MODE: \" + str(list(scipy.stats.mode(results))[0][0])) \n",
    "print(\"MODE vowels only: \" + str(list(scipy.stats.mode(vowel_results))[0][0])) ## Vowels only\n",
    "#print(\"All samples: \"+str(np.mean(results)))\n",
    "#print(\"Vowels only: \"+str(np.mean(vowel_results)))\n",
    "\n",
    "mode_id, mode_id_percentage = most_common_class(vowel_results)\n",
    "top_label = speaker_list[mode_id]\n",
    "\n",
    "print('')\n",
    "print(\"Speaker: \" + str(top_label))\n",
    "print(\"Confidence: \" + str(mode_id_percentage))\n",
    "\n",
    "print('')\n",
    "\n",
    "print(str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that classifies vowel segments only and returns \n",
    "## average output for the full clip\n",
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs = np.array(attk.get_mfccs_and_deltas(clip_pathname, n_mfcc=30, n_fft=8192))\n",
    "    mfccs = scaler.transform(mfccs)\n",
    "    results = list(classifier.predict(mfccs))  ## Predicting new observation\n",
    "    return most_common_class(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "os.chdir('/sharedfolder/applause_classifier/test_clips/')\n",
    "!rm *_3_sec_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Classifying a long audio file\n",
    "\n",
    "resolution_secs = 1\n",
    "classifier_threshold = 0.30\n",
    "\n",
    "os.chdir('/sharedfolder/applause_classifier/test_clips/')\n",
    "#os.chdir('/sharedfolder/')\n",
    "\n",
    "errors = []\n",
    "\n",
    "import datetime\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "\n",
    "media_path = \"/sharedfolder/applause_classifier/test_clips/LM_03_John-Prine_1976-06-13_CAS_A_SRM.wav\"\n",
    "\n",
    "#os.chdir('/sharedfolder/The_World_batch/The_World_WGBH_episodes/')\n",
    "\n",
    "#media_path = random.choice([item for item in os.listdir('./') if '.wav' in item])\n",
    "\n",
    "time_str = str(datetime.datetime.now()).replace(':', '').split('.')[0].replace(' ', '_')\n",
    "\n",
    "csv_path = media_path[:-4]+'_applause_mlpc4096_labels_100-500Hz_scaled_'+str(resolution_secs)+'s_' + time_str +'.csv'\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications = []\n",
    "with open(csv_path,'w') as fo:\n",
    "    fo.write('')\n",
    "\n",
    "for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "    try:\n",
    "        snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "        mode_id, mode_id_percentage = classify_clip('/tmp/temp_clip.wav')\n",
    "        os.remove('/tmp/temp_clip.wav')\n",
    "        \n",
    "        top_label = speaker_list[mode_id]\n",
    "        if mode_id_percentage > classifier_threshold:\n",
    "            with open(csv_path,'a') as fo:\n",
    "                duration = resolution_secs\n",
    "                start = i * resolution_secs\n",
    "                fo.write(str(start) + ',' + str(duration) +','+ str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')\n",
    "    except Exception as e:\n",
    "        errors.append(e)\n",
    "        print(\"Error: \" + str(i))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## BATCH classifying long audio files\n",
    "\n",
    "resolution_secs = 1\n",
    "classifier_threshold = 0.30\n",
    "\n",
    "\n",
    "errors = []\n",
    "\n",
    "import datetime\n",
    "\n",
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "\n",
    "media_dir = \"/sharedfolder/applause_classifier/LM_Live_Recordings/\"\n",
    "\n",
    "os.chdir(media_dir)\n",
    "media_paths = [item for item in os.listdir('./') if (item[-4:].lower() in ('.mp3','.wav','.mp4')) & (item[0]!='.')]\n",
    "random.shuffle(media_paths)\n",
    "\n",
    "for media_path in media_paths:\n",
    "\n",
    "    time_str = str(datetime.datetime.now()).replace(':', '').split('.')[0].replace(' ', '_')\n",
    "\n",
    "    csv_path = media_path[:-4]+'_applause_mlpc4096_labels_100-16kHz_scaled_'+str(resolution_secs)+'s_' + time_str +'.csv'\n",
    "\n",
    "    snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "    classifications = []\n",
    "    with open(csv_path,'w') as fo:\n",
    "        fo.write('')\n",
    "\n",
    "    for i in range(int(attk.duration(media_path)/resolution_secs)):\n",
    "        try:\n",
    "            snd.subclip(i * resolution_secs , (i * resolution_secs) + resolution_secs).write_audiofile('/tmp/temp_clip.wav')\n",
    "            mode_id, mode_id_percentage = classify_clip('/tmp/temp_clip.wav')\n",
    "            os.remove('/tmp/temp_clip.wav')\n",
    "\n",
    "            top_label = speaker_list[mode_id]\n",
    "            if mode_id_percentage > classifier_threshold:\n",
    "                if mode_id==0:\n",
    "                    with open(csv_path,'a') as fo:\n",
    "                        duration = resolution_secs\n",
    "                        start = i * resolution_secs\n",
    "                        fo.write(str(start) + ',' + str(duration) +','+ str(mode_id) +','+ str(mode_id_percentage) + ',' + str(top_label) + '\\n')\n",
    "        except Exception as e:\n",
    "            errors.append(e)\n",
    "            print(\"Error: \" + str(i))\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time elapsed: \"+str(timeit.default_timer() - tic))\n",
    "os.system(\"printf '\\a'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(errors))\n",
    "print(list(set([item[0] for item in errors])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
