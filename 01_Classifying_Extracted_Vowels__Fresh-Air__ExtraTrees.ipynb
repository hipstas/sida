{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install the latest version of attk (if necessary)\n",
    "#!pip install -U git+git://github.com/hipstas/audio-tagging-toolkit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from IPython.display import display, Audio\n",
    "import timeit\n",
    "import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/')\n",
    "\n",
    "!mkdir /sharedfolder/GitHub/sida/___training_audio\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio')\n",
    "\n",
    "## Uncomment lines below to download audio files for training\n",
    "\n",
    "#!wget http://www.stephenmclaughlin.net/HILT/audio_corpora/NPR_Fresh_Air_diarized.zip\n",
    "#!unzip NPR_Fresh_Air_diarized.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading label data CSV as a list of lists\n",
    "\n",
    "csv_url = \"https://raw.githubusercontent.com/hipstas/aapb-labels/master/Terry_Gross/Terry_Gross_labels.csv\"\n",
    "\n",
    "csv_string = urllib2.urlopen(csv_url)\n",
    "\n",
    "train_table = []\n",
    "\n",
    "csv_reader = unicodecsv.reader(csv_string)\n",
    "\n",
    "for row in csv_reader:\n",
    "        train_table.append(row)\n",
    "\n",
    "train_table[:10]+['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing header row if present\n",
    "\n",
    "if 'Media file basename' in train_table[0]:\n",
    "    train_table = train_table[1:]\n",
    "\n",
    "random.shuffle(train_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Excerpting labeled WAV clips\n",
    "\n",
    "training_audio_pathname = \"NPR_Fresh_Air_diarized\"\n",
    "out_dir = '_classes_' + training_audio_pathname\n",
    "\n",
    "\n",
    "for row in train_table:\n",
    "    try:\n",
    "        basename , start, duration, class_name, labeled_by = row  ## Assigning values in row to variables\n",
    "        filename = str(basename + '.mp3')\n",
    "        start = float(start)\n",
    "        end = float(start) + float(duration)\n",
    "        out_pathname = str(os.path.join(out_dir, class_name.replace(' ','_')))\n",
    "        try: \n",
    "            subprocess.call(['mkdir', '-p', out_pathname])\n",
    "        except:\n",
    "            pass\n",
    "        attk.subclip(os.path.join(training_audio_pathname, filename), float(start), end, out_pathname) ## <- attk\n",
    "    except Exception as e: \n",
    "        print(row)\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_pairs(media_path,vowel_ranges):\n",
    "    snd = AudioFileClip.AudioFileClip(media_path)\n",
    "    file_duration = attk.duration(media_path)\n",
    "    for pair in vowel_ranges:\n",
    "        if int(pair[1]) >= 4:\n",
    "            start, duration = pair\n",
    "            start=float(start)*(512/44100.0)\n",
    "            duration=float(duration)*(512/44100.0)\n",
    "            if start + duration > file_duration:\n",
    "                duration = file_duration - start\n",
    "            basename = media_path.split('/')[-1][:-4]\n",
    "            out_filename = basename+'_'+str(start)+'_'+str(duration)+'.wav'\n",
    "            snd.subclip(float(start),float(start)+float(duration)).write_audiofile(os.path.join('_vowel_clips',out_filename))\n",
    "\n",
    "\n",
    "def batch_extract_vowels(media_dir):\n",
    "\n",
    "    starting_location = os.getcwd()\n",
    "    \n",
    "    os.chdir(media_dir)\n",
    "\n",
    "    try: os.mkdir('_vowel_clips')\n",
    "    except: pass\n",
    "\n",
    "    filenames=[item for item in os.listdir('./') if item[-4:].lower() in ('.mp3','.wav')]\n",
    "\n",
    "    tic=timeit.default_timer()\n",
    "\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            vowel_bools = attk.get_vowel_segments(filename)\n",
    "            vowel_ranges = attk.labels_to_ranges(vowel_bools, label=True)\n",
    "            extract_pairs(filename,vowel_ranges)\n",
    "        except: print(\"***** ERROR: \"+filename)\n",
    "\n",
    "    print(\"Time elapsed: \"+str(timeit.default_timer() - tic))\n",
    "\n",
    "    os.chdir(starting_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#for class_dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "#    batch_extract_vowels(class_dir_name)\n",
    "\n",
    "batch_extract_vowels('Terry_Gross')\n",
    "batch_extract_vowels('Background_Speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs=get_mfccs_and_deltas(clip_pathname)\n",
    "    results = random_forest.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = get_vowel_segments(clip_pathname)[::2]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only\n",
    "\n",
    "\n",
    "def seconds_list_to_ranges(seconds_list): \n",
    "    ranges = []                \n",
    "    for k, g in groupby(enumerate(seconds_list), lambda (i,x):i-x):\n",
    "        group = map(itemgetter(1), g)\n",
    "        ranges.append((group[0], group[-1]))\n",
    "    return ranges\n",
    "\n",
    "seconds_list_to_ranges([1,2,3,7,8,9,34,99,100,101,102,199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "speaker_1_mfccs = []\n",
    "\n",
    "for filename in os.listdir('_classes/Carol_Hills/_vowel_clips'):\n",
    "    if '.wav' in filename:\n",
    "        speaker_1_mfccs += attk.get_mfccs_and_deltas('_classes/Carol_Hills/_vowel_clips/'+filename)\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n",
    "\n",
    "bg_mfccs = []\n",
    "\n",
    "for filename in os.listdir('_classes/Background_Speaker/_vowel_clips'):\n",
    "    if '.wav' in filename:\n",
    "        bg_mfccs += attk.get_mfccs_and_deltas('_classes/Background_Speaker/_vowel_clips/'+filename)\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Decision tree\n",
    "\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "X = speaker_1_mfccs[:-len(speaker_1_mfccs)/10] + bg_mfccs[:-len(bg_mfccs)/10]\n",
    "y = [0]*len(speaker_1_mfccs[:-len(speaker_1_mfccs)/10]) + [1]*len(bg_mfccs[:-len(bg_mfccs)/10])\n",
    "\n",
    "X_test = speaker_1_mfccs[-len(speaker_1_mfccs)/10:] + bg_mfccs[-len(bg_mfccs)/10:]\n",
    "y_test = [0]*len(speaker_1_mfccs[-len(speaker_1_mfccs)/10:]) + [1]*len(bg_mfccs[-len(bg_mfccs)/10:])\n",
    "\n",
    "classifier = ExtraTreesClassifier().fit(X, y)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(classifier,'hills_vowels_extratrees_2048.pkl')\n",
    "classifier=joblib.load('hills_vowels_extratrees_2048.pkl')\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading pre-trained model\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#random_forest=joblib.load('pesca_vowels_random_forest_2048.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs=get_mfccs_and_deltas(clip_pathname)\n",
    "    results = random_forest.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = get_vowel_segments(clip_pathname)[::2]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "filename = random.choice(os.listdir('unseen/'))\n",
    "test_pathname = 'unseen/'+filename\n",
    "test_mfccs=attk.get_mfccs_and_deltas(test_pathname)\n",
    "\n",
    "print(test_pathname)\n",
    "\n",
    "results = classifier.predict(test_mfccs)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = get_vowel_segments(test_pathname)[::2]\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if vowel_bools[i]==True:\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(test_pathname))\n",
    "\n",
    "\n",
    "print(\"All: \"+str(np.mean(results)))\n",
    "print(\"Vowels only: \"+str(np.mean(vowel_results)))\n",
    "\n",
    "#print(\"Time elapsed: \"+str(timeit.default_timer() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(get_vowel_segments(test_pathname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Classifying a long audio file\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "\n",
    "media_path = \"/sharedfolder/3_training_classes/unseen_full_episodes/SM5931850435.mp3\"\n",
    "\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications=[]\n",
    "\n",
    "for i in range(int(media_duration(media_path))):\n",
    "    try:\n",
    "        snd.subclip(i,i+1).write_audiofile('/tmp/temp_clip.wav')\n",
    "        classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "    except: print('missed one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing classification output to CSV\n",
    "\n",
    "counter=0\n",
    "\n",
    "class_0_secs=[]\n",
    "class_1_secs=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "for classification in smooth(np.array(classifications)):\n",
    "    if classification < 0.34:\n",
    "        class_0_secs.append(i)\n",
    "    if classification > 0.38:\n",
    "        class_1_secs.append(i)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "counter=0\n",
    "\n",
    "csv_path=media_path[:-4]+'_extratrees2048_labels.csv'\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    for pair in seconds_list_to_ranges(class_0_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Pesca\\n')\n",
    "    for pair in seconds_list_to_ranges(class_1_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Background\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
