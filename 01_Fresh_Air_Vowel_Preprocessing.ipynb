{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install the latest version of attk (if necessary)\n",
    "#!pip install -U git+git://github.com/hipstas/audio-tagging-toolkit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attk\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from IPython.display import display, Audio\n",
    "import timeit\n",
    "import random\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from sklearn.externals import joblib\n",
    "from numpy import ma\n",
    "from aubio import source, pitch\n",
    "from moviepy.audio.io import AudioFileClip\n",
    "import subprocess\n",
    "import unicodecsv\n",
    "import urllib2\n",
    "import csv\n",
    "\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/')\n",
    "\n",
    "!mkdir /sharedfolder/GitHub/sida/___training_audio\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio')\n",
    "\n",
    "## Uncomment lines below to download audio files for training\n",
    "\n",
    "#!wget http://www.stephenmclaughlin.net/HILT/audio_corpora/NPR_Fresh_Air_diarized.zip\n",
    "#!unzip NPR_Fresh_Air_diarized.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading label data CSV as a list of lists\n",
    "\n",
    "## Random 1-second labels\n",
    "#csv_url = \"https://raw.githubusercontent.com/hipstas/aapb-labels/master/Terry_Gross/Terry_Gross_labels.csv\"\n",
    "\n",
    "## Labels done by hand in Sonic Visualiser\n",
    "csv_url = 'https://raw.githubusercontent.com/hipstas/aapb-labels/master/Terry_Gross/Terry_Gross_corrected_SV.csv'\n",
    "\n",
    "csv_string = urllib2.urlopen(csv_url)\n",
    "\n",
    "train_table = []\n",
    "\n",
    "csv_reader = unicodecsv.reader(csv_string)\n",
    "\n",
    "for row in csv_reader:\n",
    "        train_table.append(row)\n",
    "\n",
    "train_table[:10]+['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Removing header row if present\n",
    "\n",
    "if 'Media file basename' in train_table[0]:\n",
    "    train_table = train_table[1:]\n",
    "\n",
    "random.shuffle(train_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Excerpting WAV clips corresponding to labels\n",
    "\n",
    "training_audio_pathname = \"NPR_Fresh_Air_diarized\"\n",
    "out_dir = '_classes_SV_' + training_audio_pathname\n",
    "\n",
    "\n",
    "for row in train_table:\n",
    "    try:\n",
    "        basename , start, duration, class_name, labeled_by = row  ## Assigning values in row to variables\n",
    "        filename = str(basename + '.mp3')\n",
    "        start = float(start)\n",
    "        end = float(start) + float(duration)\n",
    "        out_pathname = str(os.path.join(out_dir, class_name.replace(' ','_')))\n",
    "        try: \n",
    "            subprocess.call(['mkdir', '-p', out_pathname])\n",
    "        except:\n",
    "            pass\n",
    "        attk.subclip(os.path.join(training_audio_pathname, filename), float(start), end, out_pathname) ## <- attk\n",
    "    except Exception as e: \n",
    "        print(row)\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_pairs(media_path,vowel_time_ranges):\n",
    "    snd = AudioFileClip.AudioFileClip(media_path)\n",
    "    file_duration = attk.duration(media_path)\n",
    "    for pair in vowel_time_ranges:\n",
    "        start, end = pair\n",
    "        start=float(start)\n",
    "        end=float(end)\n",
    "        if end-start >= 0.1:  ## Ignore clips shorter than 0.1 second\n",
    "            basename = media_path.split('/')[-1][:-4]\n",
    "            out_filename = basename+'__'+str(round(start, 4))+'_'+str(round(end, 4))+'.wav'\n",
    "            snd.subclip(start, end).write_audiofile(os.path.join('_vowel_clips',out_filename))\n",
    "\n",
    "\n",
    "def batch_extract_vowels(media_dir):\n",
    "\n",
    "    starting_location = os.getcwd()\n",
    "    \n",
    "    os.chdir(media_dir)\n",
    "\n",
    "    bin_2048_to_sec_constant = 0.046439909297052155\n",
    "    \n",
    "    try: os.mkdir('_vowel_clips')\n",
    "    except: pass\n",
    "\n",
    "    filenames=[item for item in os.listdir('./') if item[-4:].lower() in ('.mp3','.wav','.mp4')]\n",
    "\n",
    "    tic=timeit.default_timer()\n",
    "\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            vowel_bools = attk.get_vowel_segments(filename)\n",
    "\n",
    "            vowel_bin_ranges = attk.labels_to_ranges(vowel_bools, label=True)\n",
    "\n",
    "            vowel_time_ranges = [(s*bin_2048_to_sec_constant, e*bin_2048_to_sec_constant) for s, e in vowel_bin_ranges]\n",
    "            \n",
    "            extract_pairs(filename,vowel_time_ranges)\n",
    "\n",
    "        except: print(\"***** ERROR: \"+filename)\n",
    "\n",
    "    print(\"Time elapsed: \"+str(timeit.default_timer() - tic))\n",
    "\n",
    "    os.chdir(starting_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_SV_NPR_Fresh_Air_diarized')\n",
    "\n",
    "#for class_dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "#    batch_extract_vowels(class_dir_name)\n",
    "\n",
    "batch_extract_vowels('Terry_Gross')\n",
    "#batch_extract_vowels('Background_Speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized')\n",
    "\n",
    "#for class_dir_name in [item for item in os.listdir('./') if os.path.isdir(item)]:\n",
    "#    batch_extract_vowels(class_dir_name)\n",
    "\n",
    "batch_extract_vowels('Terry_Gross')\n",
    "batch_extract_vowels('Background_Speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "os.chdir('/Volumes/U/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017')\n",
    "\n",
    "batch_extract_vowels('Female')\n",
    "batch_extract_vowels('Male')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "os.chdir('/sharedfolderGitHub/sida/___training_audio/_classes_SV_NPR_Fresh_Air_diarized/')\n",
    "\n",
    "\n",
    "dir_names = [item for item in os.listdir('./') if os.path.isdir(item)]\n",
    "\n",
    "for dir_name in dir_names:\n",
    "    \n",
    "    os.chdir('/sharedfolderGitHub/sida/___training_audio/_classes_SV_NPR_Fresh_Air_diarized/' + dir_name + '/_vowel_clips')\n",
    "    \n",
    "    try: os.mkdir('../_vowel_mfccs_and_deltas')\n",
    "    except: pass\n",
    "    \n",
    "    for filename in [item for item in os.listdir('./') if item.lower()[-4:] == '.wav']:\n",
    "        mfccs = attk.get_mfccs_and_deltas(filename)\n",
    "        with open('../_vowel_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv', 'w') as fo:\n",
    "            csv_writer = csv.writer(fo)\n",
    "            csv_writer.writerows(mfccs)  \n",
    "\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "os.chdir('/sharedfolderGitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized/')\n",
    "\n",
    "dir_names = [item for item in os.listdir('./') if os.path.isdir(item)]\n",
    "\n",
    "for dir_name in dir_names:\n",
    "    \n",
    "    try:\n",
    "        os.chdir('/sharedfolderGitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized/' + dir_name + '/_vowel_clips')\n",
    "    \n",
    "        try: os.mkdir('../_vowel_mfccs_and_deltas')\n",
    "        except: pass\n",
    "    \n",
    "        for filename in [item for item in os.listdir('./') if item.lower()[-4:] == '.wav']:\n",
    "            mfccs = attk.get_mfccs_and_deltas(filename)\n",
    "            with open('../_vowel_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv', 'w') as fo:\n",
    "                csv_writer = csv.writer(fo)\n",
    "                csv_writer.writerows(mfccs)  \n",
    "    except: pass\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extracting features\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "os.chdir('/Volumes/U/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017')\n",
    "\n",
    "dir_names = [item for item in os.listdir('./') if os.path.isdir(item)]\n",
    "\n",
    "for dir_name in dir_names:\n",
    "    \n",
    "    try:\n",
    "        os.chdir('/Volumes/U/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017/' + dir_name + '/_vowel_clips')\n",
    "    \n",
    "        try: os.mkdir('../_vowel_mfccs_and_deltas')\n",
    "        except: pass\n",
    "    \n",
    "        for filename in [item for item in os.listdir('./') if item.lower()[-4:] == '.wav']:\n",
    "            mfccs = attk.get_mfccs_and_deltas(filename)\n",
    "            with open('../_vowel_mfccs_and_deltas/' + filename[:-4] + '.mfcc.csv', 'w') as fo:\n",
    "                csv_writer = csv.writer(fo)\n",
    "                csv_writer.writerows(mfccs)  \n",
    "    except: pass\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "speaker_1_mfccs = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    if '.wav' in filename:\n",
    "        speaker_1_mfccs += attk.get_mfccs_and_deltas(filename)\n",
    "\n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "##\n",
    "print(len(speaker_1_mfccs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_NPR_Fresh_Air_diarized/Background_Speaker/_vowel_clips')\n",
    "\n",
    "bg_mfccs = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    if '.wav' in filename:\n",
    "        bg_mfccs += attk.get_mfccs_and_deltas(filename)\n",
    "\n",
    "        \n",
    "print(timeit.default_timer() - tic)\n",
    "\n",
    "print(len(bg_mfccs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017/Male/_vowel_mfccs_and_deltas')\n",
    "\n",
    "m_features = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    with open(filename) as fi:\n",
    "        csv_reader = csv.reader(fi)\n",
    "        for row in csv_reader:\n",
    "            m_features.append([float(item) for item in row])\n",
    "\n",
    "print(len(m_features))\n",
    "\n",
    "\n",
    "os.chdir('/sharedfolder/GitHub/sida/___training_audio/_classes_ubm_clips_final_July_2017/Female/_vowel_mfccs_and_deltas')\n",
    "\n",
    "f_features = []\n",
    "\n",
    "for filename in os.listdir('./'):\n",
    "    with open(filename) as fi:\n",
    "        csv_reader = csv.reader(fi)\n",
    "        for row in csv_reader:\n",
    "            f_features.append([float(item) for item in row])\n",
    "\n",
    "print(len(f_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bg_mfccs += f_features\n",
    "bg_mfccs += m_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "speaker_1_mfccs = speaker_1_mfccs[::-1]\n",
    "bg_mfccs = bg_mfccs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision tree\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "X = speaker_1_mfccs[:-len(speaker_1_mfccs)/10] + bg_mfccs[:-len(bg_mfccs)/10]\n",
    "y = [0]*len(speaker_1_mfccs[:-len(speaker_1_mfccs)/10]) + [1]*len(bg_mfccs[:-len(bg_mfccs)/10])\n",
    "\n",
    "X_test = speaker_1_mfccs[-len(speaker_1_mfccs)/10:] + bg_mfccs[-len(bg_mfccs)/10:]\n",
    "y_test = [0]*len(speaker_1_mfccs[-len(speaker_1_mfccs)/10:]) + [1]*len(bg_mfccs[-len(bg_mfccs)/10:])\n",
    "\n",
    "classifier = ExtraTreesClassifier().fit(X, y)\n",
    "\n",
    "## Saving trained model\n",
    "joblib.dump(classifier,'gross_vowels_et_2048.pkl')\n",
    "classifier=joblib.load('gross_vowels_et_2048.pkl')\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs=get_mfccs_and_deltas(clip_pathname)\n",
    "    results = random_forest.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = get_vowel_segments(clip_pathname)[::2]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading pre-trained model\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#random_forest=joblib.load('pesca_vowels_random_forest_2048.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_clip(clip_pathname):\n",
    "    mfccs=get_mfccs_and_deltas(clip_pathname)\n",
    "    results = classifier.predict(mfccs)  ## Predicting new observation\n",
    "    vowel_results=[]\n",
    "    vowel_bools = get_vowel_segments(clip_pathname)[::2]\n",
    "\n",
    "    for i in range(len(results)):\n",
    "        if vowel_bools[i]==True:\n",
    "            vowel_results.append(results[i])\n",
    "\n",
    "    return np.mean(vowel_results) ## Vowels only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Classifying short clips\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "filename = random.choice(os.listdir('unseen/'))\n",
    "test_pathname = 'unseen/'+filename\n",
    "test_mfccs=attk.get_mfccs_and_deltas(test_pathname)\n",
    "\n",
    "print(test_pathname)\n",
    "\n",
    "results = classifier.predict(test_mfccs)  ## Predicting new observation\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    "vowel_results=[]\n",
    "\n",
    "vowel_bools = get_vowel_segments(test_pathname)[::2]\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if vowel_bools[i]==True:\n",
    "        vowel_results.append(results[i])\n",
    "\n",
    "display(Audio(test_pathname))\n",
    "\n",
    "\n",
    "print(\"All: \"+str(np.mean(results)))\n",
    "print(\"Vowels only: \"+str(np.mean(vowel_results)))\n",
    "\n",
    "#print(\"Time elapsed: \"+str(timeit.default_timer() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(get_vowel_segments(test_pathname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du /tmp/temp_clip.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Classifying a long audio file\n",
    "\n",
    "\n",
    "tic=timeit.default_timer()\n",
    "\n",
    "\n",
    "media_path = \"/sharedfolder/fa_eval/FA_Author_Tom_Perrotta.mp3\"\n",
    "\n",
    "\n",
    "snd = AudioFileClip.AudioFileClip(media_path)\n",
    "\n",
    "classifications=[]\n",
    "\n",
    "for i in range(int(attk.duration(media_path))):\n",
    "    try:\n",
    "        snd.subclip(i,i+1).write_audiofile('/tmp/temp_clip.wav')\n",
    "        classifications.append(classify_clip('/tmp/temp_clip.wav'))\n",
    "    except: print('missed one')\n",
    "\n",
    "classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing classification output to CSV\n",
    "\n",
    "counter=0\n",
    "\n",
    "class_0_secs=[]\n",
    "class_1_secs=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "for classification in attk.smooth(np.array(classifications)):\n",
    "    if classification < 0.34:\n",
    "        class_0_secs.append(i)\n",
    "    if classification > 0.38:\n",
    "        class_1_secs.append(i)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "counter=0\n",
    "\n",
    "csv_path=media_path[:-4]+'_extratrees2048_labels.csv'\n",
    "\n",
    "with open(csv_path,'w') as fo:\n",
    "    for pair in seconds_list_to_ranges(class_0_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Terry Gross\\n')\n",
    "    for pair in seconds_list_to_ranges(class_1_secs):\n",
    "        fo.write(str(float(pair[0]))+','+str(float(pair[1]))+',Background\\n')\n",
    "\n",
    "\n",
    "print(timeit.default_timer() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
